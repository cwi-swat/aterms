%
% File: apigen.ltx
%
% $Id$
%

\documentclass{elsart}

% {{{  packages

\usepackage{verbatim}

% }}}
% {{{  commands

\newcommand{\C}{\mbox{\sc C}}
\newcommand{\adt}{\mbox{\sc adt}}
\newcommand{\afun}{\texttt{AFun}}
\newcommand{\api}{\mbox{\sc api}}
\newcommand{\asdf}{\mbox{\sc Asf+Sdf}}
\newcommand{\asfix}{\mbox{AsFix}}
\newcommand{\asf}{\mbox{\sc Asf}}
\newcommand{\aterms}{\mbox{ATerms}}
\newcommand{\aterm}{\mbox{ATerm}}
\newcommand{\atlib}{\mbox{ATerm-Library}}
\newcommand{\autocode}{\mbox{\sc autocode}}
\newcommand{\java}{\mbox{\sc Java}}
\newcommand{\metaenv}{{\sc Asf+Sdf}\ Meta-En\-vir\-on\-ment}
\newcommand{\sdf}{\mbox{\sc Sdf}}

% }}}

\begin{document}

% {{{  Frontmatter

\begin{frontmatter}

\title{Generation of Abstract Programming Interfaces \\
  from Syntax Definitions \\
  $Revision$}

\author{H.A. de Jong \and P.A. Olivier}
\address{
  CWI, Department of Software Engineering, \\
  Kruislaan 413,
  1098 SJ Amsterdam,
  The Netherlands
}

\begin{abstract}
\label{abstract}

Using the \atlib\ to represent tree-like datastructures has become a
popular activity, especially to developers of e.g. lexical scanners,
parsers, rewrite engines and model checkers. Practical experience with the
\atlib\ in the \metaenv\ has shown that the development and maintenance
of tools that access \aterms\ using handcrafted code is involved and
very error prone. Both the \emph{make and match} paradigm and the
\emph{direct manipulation} of \aterms\ suffer from the fact that the
programmer uses knowledge about the underlying structure of the \aterm\
that represents the data type being accessed. Hardwiring this knowledge
in various tools makes it difficult to maintain the tools with respect
to changes in the datastructure.

By lifting the data definition and its mapping to an \aterm\
representation from the level of tool implementation, it becomes possible
to generate a library of access functions on the data type, which can be
used by all the tools that need access to it. The tools no longer directly
manipulate the \aterm\ representation, but rather invoke methods described
by the \api\ of the library, thus abstracting from the fact that \aterms\
are used for the implementation of the data type.

This paper describes how an \api\ and its implementation can be generated
from a syntax definition of the data type. In particular we describe
how an annotated \sdf\ specification can be used to generate a library
of access functions that manipulate the parse trees of terms over this
syntax. Application of this technique in the \metaenv\ has resulted in
a spectacular elimination of 25\% of the handwritten code, thus greatly
improving both maintainability of the tools and their flexibility with
respect to changes in the parsetree format.

\end{abstract}

\end{frontmatter}

% }}}
% {{{  Introduction


\section{Introduction}
\label{sec:intro}

Since the development of the \atlib~\cite{BJKO2000} in 1999, its use
for the implementation of tree-like data structures has become quite
popular amongst developers of scanners, parsers, rewrite engines and
model checkers. Apart from its inevitable deployment in the tools of the
\metaenv\ for which it was specifically designed, the \atlib\ is used
amongst others in: \texttt{todo: complete refs, name more examples} the
ELAN system~\cite{BR01}, Stratego~\cite{Vis01.rta}, CASL, muCRL toolkit?

As more and more tools in the \metaenv\ were converted to work with
the \atlib, it became apparent that the tools had become inflexible with
respect to changes in the parse tree format (called \asfix), and were hard
to maintain. Evidence supporting these claims were the frequent use of
handcrafted \aterm-patterns: literal strings of characters representing
a matching pattern, characterized by many backslash-escaped quotes,
illegible sequences of closing parentheses, braces and square brackets,
and the presence of typed placeholders.

The use of these patterns is not in any way restricted to the realm of
parse trees. In fact, anyone who has programmed with the \atlib, will
probably be familiar with patterns such as \texttt{and(<bool>,<bool>)}.
In this simple form these patterns are quite easy to work with and they
are to some extent even pleasing to the eye. But as these patterns
become longer and more intricate with a liberal sprinkling of quoted
strings containing backslash-escaped quotes, and as they begin to contain
lists and annotations, the once so simple \emph{make-and-match} paradigm
becomes a developer's nightmare.

Motivated by the desire to change \asfix\ and to avoid the herculean
maintenance task this operation would impose on our tools, we decided
to remove as much ``\aterm-handicraft'' from the tools as possible
by developing an \api-generator that creates both an interface and an
implementation of data structures represented by \aterms.

While maintaining the advantages of the \atlib\ (in our case most notably
its efficiency due to maximal subterm sharing), applications built with
this generated \api\ benefit from improved simplicity and readability,
are easier to maintain and are more robust against changes in the
underlying \asfix\ representation.

This paper describes how an annotated grammar or syntax definition
can be used to generate a library of functions that provide access to
the parse trees of terms over this grammar. In particular we describe
how a \sdf-specification commonly found when using the \metaenv\ is
used to collect the information necessary to build a mapping between
grammar productions and their \aterm-pattern in the underlying \asfix\
parse tree, and how this mapping is subsequently used to generate \C\
functions that provide an \api\ to these parse trees.

Before getting to the core of the generation scheme, we
present introductory sections on the specification formalism
\asdf\ (Section~\ref{sec:asdf-nutshell}), the syntax of
\aterms\ (Section~\ref{sec:aterm-syntax}), and \asfix\
(Section~\ref{sec:asfix-syntax}).

% {{{  subsection{\asdf\ in a nutshell}

\subsection{\asdf\ in a nutshell}
\label{sec:asdf-nutshell}

The specification formalism \asdf~\cite{BHK89,HHKR92} is a combination of
the algebraic specification formalism \asf\ and the syntax definition
formalism \sdf. An overview can be found in~\cite{DHK96}. As an
illustration, Figure~\ref{fig:bool-example} presents the definition of
the Boolean datatype in \asdf. \asdf\ specifications consist of modules,
where each module has an \sdf-part (defining lexical and context-free
syntax) and an \asf-part (defining equations). The \sdf\ part corresponds
to signatures in ordinary algebraic specification formalisms. However,
syntax is not restricted to plain prefix notation but instead arbitrary
context-free grammars can be defined. The syntax defined in the \sdf-part
of a module can be used immediately when defining equations, thus making
the syntax used in equations \emph{user-defined}.

% {{{  fig:bool-example

\begin{figure}
\begin{scriptsize}
\hrulefill
\verbatiminput{bool.example}
\caption{\label{fig:bool-example} \asdf\ specification of the Booleans}
\hrulefill
\end{scriptsize}
\end{figure}

% }}}

The equations appearing in the \asf-part of a specification have the
following distinctive features:

\begin{itemize}
  \item Conditional equations with positive and negative conditions.
  \item Non left-linear equations.
  \item List matching.
  \item Default equations.
\end{itemize}

It is possible to execute specifications by interpreting the equations as
conditional rewrite rules.  The semantics of \asdf\ are based on innermost
rewriting. Default equations are tried when all other applicable equations
have failed, either because the arguments did not match or because one
of the conditions failed.

One of the powerful features of the \asdf\ specification language is
list matching. Figure~\ref{fig:set-example} shows a single equation which
removes multiple occurrences of identifiers from a set. In this example,
variables with a {\tt *} in their name are list-variables that may match
zero or more identifiers. The implementation of list matching may involve
backtracking to find a match that satisfies the left-hand side of the
rewrite rule as well as all of its conditions. Backtracking is only
performed within the scope of a rewrite rule, so if the right-hand side
of the rewrite rule is normalized and this normalization fails {\em no}
backtracking is performed to find a new match.

The development of \asdf\ specifications is supported by an interactive
programming environment, the \metaenv~\cite{Kli93}. In this environment
specifications can be developed and tested. It provides syntax-directed
editors, a parser generator, and a rewrite engine. Given this rewrite
engine terms can be reduced by interpreting the equations as rewrite
rules. For instance, the term
\begin{quote}
  {\tt true \& ( false | true )}
\end{quote}

reduces to {\tt true} when applying the equations of
Figure~\ref{fig:bool-example}.

% {{{  fig:set-example

\begin{figure}
\begin{scriptsize}
\hrulefill
\verbatiminput{set.example}
\caption{\label{fig:set-example} \asdf\ specification of the Set equation}
\hrulefill
\end{scriptsize}
\end{figure}

% }}}

% }}}
% {{{  \subsection{Annotated Terms: the \aterm\ syntax}

\subsection{Annotated Terms: the \aterm\ syntax}
\label{sec:aterm-syntax}

The definition of the concrete syntax of \aterms\ is given in
Appendix~\ref{app:aterm-syntax}. Here are a number of examples to
(re-)familiarize the reader with some of the features of the textual
representation of \aterms:

\begin{itemize}

\item Integer and real constants are written conventionally: \texttt{1},
\texttt{3.14}, and \texttt{-0.7E34} are all valid \aterms.

\item Function applications are represented by a function name followed
by an open parenthesis, a list of arguments separated by commas, and a
closing parenthesis. When there are no arguments, the parentheses may be
omitted. Examples are: \texttt{f(a,b)} and \texttt{"test!"(1,2.1,"Hello
world!")}. These examples show that double quotes can be used to delimite
function names that are not identifiers.

\item Lists are represented by an opening square bracket, a number
of list elements separated by commas and a closing square bracket:
\texttt{[1,2,"abc"]}, \texttt{[]}, and \texttt{[f,g([1,2],x)]} are
examples.

\item A placeholder is represented by an opening angular bracket followed
by a subterm and a closing angular bracket. Examples are: \texttt{<int>},
\texttt{<[3]>}, and \texttt{<f(<int>,<real>)>}.

\end{itemize}

% }}}
% {{{  \subsection{\asdf\ Parse Trees: the \asfix\ syntax}

\subsection{\asdf\ Parse Trees for Dummies: \asfix\ explained}
\label{sec:asfix-syntax}

From a \sdf-specification, a parse table can be generated using the
\texttt{pgen} tool from the \metaenv. This parse table can subsequently
be used by \texttt{sglr}: the scannerless, generalized LR parser to
parse input terms over the syntax described by the \sdf-specification.
The result of a succesful parse is a parse tree. The data structure used
to represent parse trees is called \asfix, and is implemented using the
\atlib\ to exploit the maximal subterm sharing that is commonly present
in parse trees.

Because \asfix\ is a parse tree format (as opposed to an abstract syntax
tree), layout in the input term is preserved, and other syntax-derived
facts such as associativity and constructor information is made available
to any tool that has access to the \asfix\ representation of the input
term.

The definition of the concrete syntax of \asfix\ is given in
Appendix~\ref{app:asfix-syntax}, but to quickly familiarize the reader
with \asfix, we show some of its idiosyncrasies by means of real life
examples.

\hrulefill\nopagebreak

\textbf{Example: grammar production \texttt{"true" -> Bool}}

\nopagebreak
The \asfix\ representation of the \sdf\ production
\begin{quote}
  \verb+"true" -> Bool+
\end{quote}
is:
\begin{verbatim}
  prod([lit("true")],cf(sort("Bool")),no-attrs)
\end{verbatim}
\medskip
The literal \texttt{true} is the only element in the lefthand side 
of the production. It is injected into the sort \texttt{Bool}.

\hrulefill\nopagebreak

\textbf{Example: grammar production \texttt{Bool "and" Bool -> Bool {left}}}

\nopagebreak

The \asfix\ representation of the grammar production

\begin{quote}
{\footnotesize\verb+Bool "and" Bool" -> Bool {left}+}
\end{quote}

looks like this:

\begin{scriptsize}
\begin{verbatim}
 1  prod([cf(sort("Bool")),cf(opt(layout)),lit("and"),cf(opt(layout)),cf(sort("Bool"))],
 2    cf(sort("Bool")),
 3    attrs([assoc("left")]))
\end{verbatim}
\end{scriptsize}

Line $1$ declares this to be a grammar production (\texttt{prod}),
containing al the elements of the lefthand side of the production. The
\sdf-normalizer has inserted \texttt{cf(opt(layout))} subterms at exactly
those locations where optional layout in the input term is allowed.

Line $2$ tells us that the result sort of this production is \texttt{Bool}.

Line $3$ show the attributes associated with this production. In this case
the only attribute is \texttt{left} for left-associativity.

\hrulefill\nopagebreak

\textbf{Example: parsed term \texttt{true and false}}

\nopagebreak

If the input term

\begin{quote}
  \texttt{true and false}
\end{quote}

is parsed, the resulting parse tree is the production from the
previous example, applied to the actual arguments \texttt{true} and
\texttt{false}. The layout in the input term consists of exactly one
space immediately before and after the keyword \texttt{and}.

\begin{scriptsize}
\begin{verbatim}
 1 appl(
 2  prod([cf(sort("Bool")),cf(opt(layout)),lit("and"),cf(opt(layout)),cf(sort("Bool"))],
 3       cf(sort("Bool")),attrs([assoc("left")])),
 4 [appl(prod([lit("true")],cf(sort("Bool")),no-attrs),[lit("true")]),
 5  layout([" "]), lit("and"), layout([" "]),
 6  appl(prod([lit("false")],cf(sort("Bool")),no-attrs),[lit("false")])])
\end{verbatim}
\end{scriptsize}

Line $1$ states that this tree is the application of a grammar production
to a specific term.

Lines $2-3$ show the \texttt{Bool "and" Bool -> Bool {"left"}} from the previous
example.

Line 4 shows the application of the production \texttt{"true" -> Bool} to
the literal \texttt{"true"}

Line 5 are the instantiated notions of optional layout. In this case the
input term contained exactly one space immediately before and just after
the keyword \texttt{"and"}.

Line 6 is similar to Line 4, except that it represents the literal
\texttt{"false"}.

\hrulefill

The fact that many tools in the \metaenv\ need to operate on such
parse trees, raises the question of how best to access this \aterm\
representation of a data type.

% }}}

% {{{  Accessing \aterm\ Data Types

\section{Accessing \aterm\ Data Types}
\label{sec:aterm-access}

We briefly discuss the two layers of access provided by the \C\
implementation of the \atlib, and show the steps needed to gain access
to specific elements of a parse tree. Similar statements are needed in
the \java\ implementation.

% {{{  Accessing Parse Trees using the Level One interface

\subsection{Accessing Parse Trees using the Level One interface}
\label{sec:aterm-lvl1}

The level one interface offers easy to learn, but less
efficient access by using the \emph{make and match} paradigm. Terms are
constructed using \texttt{ATmake}:

% {{{  ATmake example

\begin{footnotesize}
\begin{verbatim}
  ATerm phoneTerm = ATmake("phone(<int>)", 5554242);
\end{verbatim}
\end{footnotesize}

% }}}

\noindent and elements can be extracted using \texttt{ATmatch}:

% {{{  ATmatch example

\begin{footnotesize}
\begin{verbatim}
  int number;
  ATmatch(phoneTerm, "phone(<int>)", &number);
\end{verbatim}
\end{footnotesize}

% }}}

Suppose we want to write down the \C\ code necessary to construct
the boolean term \texttt{true}. The \aterm-pattern required is quite
complex already, as we have to escape all the double quotes (the \verb+"+
characters) from interpretation by the compiler.

% {{{  Parse Tree for "true"

\begin{scriptsize}
\begin{verbatim}
 ATerm true = ATparse(
   "appl(prod([lit(\"true\")],cf(sort(\"Bool\")),no-attrs),[lit(\"true\")])");
\end{verbatim}
\end{scriptsize}

% }}}

As another example, consider a \C\ function that extracts the left-hand
side from a boolean conjunction. It needs to match the parse tree
of the incoming term against the pattern for the syntax production
for {\footnotesize\texttt{Bool "and" Bool -> Bool \{left\}} } with a
\texttt{<term>} placeholder at the correct spot. Because the pattern
is written as a \C\ string, we once again need to escape all quotes.
Moreover, the string representation of the match-pattern is so long that
it does not legibly fit on one line anymore, and we need to resort to
ANSI \C\ string concatenation\footnote{Strings can be split over multiple
lines by ending one line with a \texttt{"} and starting the next line
with another \texttt{"}.} to span the string over multiple lines.

% {{{  Level One: Extracting lhs from "Bool and Bool -> Bool"

\begin{scriptsize}
\begin{verbatim}
  ATerm extract_bool_lhs(ATerm t) {
    ATerm lhs;
    char *bool_and_lhs_pattern = 
      "appl(prod([cf(sort(\"Bool\")),cf(opt(layout)),lit(\"and\"),cf(opt(layout)),"
      "cf(sort(\"Bool\"))],cf(sort(\"Bool\")),attrs([assoc(\"left\")])),"
      "[<term>,<term>,lit("and"),<term>,<term>])";
  
    if (ATmatch(t, bool_and_lhs_pattern, &lhs, NULL, NULL, NULL)) {
      return lhs;
    }

    return NULL;
  }
\end{verbatim}
\end{scriptsize}

% }}}

Did you spot a missing quote? Are all the \verb+)+, \verb+]+, and \verb+}+
characters where they should be? Did you expect \emph{four} \texttt{<term>}
substitutions (to account for the lhs, the rhs, and the optional layout before
and after the literal \texttt{"and"})?

Keep in mind that:

\begin{itemize}

\item as long as it is a valid \C\ string, the \C\ compiler is not going to
warn you if you make a mistake (e.g. you wrote \texttt{lit(and)} instead of
\verb+lit(\"and\")+);

\item as long as it is a valid \aterm-pattern, the \aterm-library is
not going to warn you if you make a mistake (e.g. you forgot to add
\texttt{<term>} placeholders for the optional layout);

\item the only noticable effect is your application bailing out, because
the extraction function failed to come up with the desired answer;

\item your only hope to fix any problems lies in visually inspecting
the incoming term versus the expected matching pattern and figuring
out why they didn't match!

\end{itemize}

% }}}
% {{{  Accessing Parse Trees using the Level Two interface

\subsection{Accessing Parse Trees using the Level Two interface}
\label{sec:aterm-lvl2}

Extracting information from an \aterm\ using \texttt{ATmatch} is
inefficient. Each time the function is invoked, the match-pattern has
to be parsed before any matching can be done. Also, if you \emph{know}
which part of the \aterm\ you need, there is really no need to build
any sort of matching automaton. Instead you can just \emph{get} the
element you are looking for. In our boolean example, if we \emph{know}
for sure that we have a valid \texttt{and}-term, we can directly extract
its left-hand side. If, however, our incoming term can be any arbitrary
\aterm, we can no longer safely extract a subterm, we have to match the
term against the pattern for an \texttt{and}-term, to see if it even
has a left-hand side.

Therefore, if we assume as a precondition to our function that it will
always be called with a valid boolean \texttt{and}-term, we can use
more direct \aterm-calls, such as \texttt{ATgetFirst} to get the head
of a list, and \texttt{ATgetArgument} to get a specific argument from
a function application.

In particular, recalling that in \asfix\ we are dealing with
\texttt{appl(prod,[args])} patterns, the \texttt{args} are always the
second argument of the \texttt{appl}. If we look closely at the \asfix\
pattern for our \texttt{and}-terms, we notice that the left-hand side
is the first element from this list of \texttt{args}. The extraction
function can thus be simplified to the more efficient:

% {{{  Level Two: Extracting lhs from "true and false"

\begin{footnotesize}
\begin{verbatim}
  ATerm extract_bool_lhs(ATerm t) {
    ATermList args = ATgetArgument(t, 1);  // get arguments from AsFix "appl"
    return ATgetFirst(args);               // lhs is the first of these args.
  }
\end{verbatim}
\end{footnotesize}

% }}}

% }}}
% {{{  Maintenance issues

\subsection{Maintenance issues}
\label{sec:maintenance}

There are several fundamental maintenance issues inherent in the use
of \aterms\ as a data structure implementation in hand-crafted tools.

\begin{itemize}

\item The esoteric art of writing down multi-line, quote-escaped string
patterns and the subsequent substitution of parts of these patterns to
contain the desired placeholders at the correct locations, is so error
prone that it is almost guaranteed to go wrong somewhere. Practical
experience in the \metaenv\ has proven this many times over. Handcrafted
\aterm-patterns proliferate through numerous versions of various tools,
and after a while all sorts of ``mysterious'' bugs creep up where one tool
cannot handle the output of another tool, or simply bails out reporting
that deep down some part of an input term does not satisfy a particular
assertion. Obviously, these errors are often due to pattern mismatches,
misplaced placeholders, or ill-escaped quotes.

\item Even when the patterns are written down correctly, or if the Level
Two interface is used (which doesn't use \aterm-patterns), there is
much work to be done when the application syntax changes.

Suppose for example that the syntax of our boolean conjunction
changes from {\footnotesize\texttt{Bool "and" Bool -> Bool}} into
{\footnotesize\texttt{"and" "(" Bool, Bool ")" -> Bool}}.  Conceptually
nothing has changed: we mean exactly the same arguments when we address
them as the lhs, rhs, and result terms in both syntaxes.  However,
in the underlying parse tree the location of \emph{all three} subterms
has changed, which in turn means that all accessor functions we might
have written to work on boolean conjunction terms, must be adapted to
reflect these positional changes.

In fact, there is hardly any room for flexibility with respect to changes
in the syntax, unless the arguments happen to remain at their original
position. Every tool based on the modified \emph{application syntax}
has to be updated.

\item With such inflexibility with respect to the application syntax
in mind, imagine what would happen if the structure of the parse
trees (\asfix) \emph{itself} were to change! Every tool based on the
\emph{\asfix\ representation} of parse trees would have to be updated to
reflect the structural changes in the format. In our practical case of
the \metaenv\ where we wanted to rid \asfix\ of some legacy constructs
and in general needed to upgrade the format, this would have meant some
sort of modification to virtually \emph{every} tool in the \metaenv\
--- an arduous task indeed!

\end{itemize}

Although this article uses tools from the \metaenv\ as a running example,
the maintenance issues addressed here are not specific to parse trees
at all. The issues are fundamental to all applications that use \aterms\
as its data structure representation.

% }}}

% }}}

% {{{  From syntax to \api

\section{From syntax to \api}
\label{sec:syntax-to-api}

Abstracting from implementation details about the facts that there
is such a thing as a parse tree format and that this format in turn
is implemented using \aterms, it is easy to name several operations a
toolbuilder would like, given a \sdf\ syntax definition.

% {{{  What you want to be able to do, given an SDF definition

Typical things a toolbuilder would like to have, given our boolean
syntax are:

\begin{itemize}

\item A type definition for booleans (it is better to have a type
      \texttt{Bool} than to use the generic \texttt{ATerm} type);

\item Create the basic booleans: \texttt{true}, and \texttt{false};

\item Create a compound boolean term using basic and other compound boolean terms;

\item Given an arbitrary term, ask: \emph{is this a valid boolean term?}

\item Given an arbitrary boolean term, distinguish between a basic term
      and a compound term, e.g. by asking: \emph{Does this boolean have
      a left-hand side?}

\item Give me the right-hand side of this boolean term;

\item Replace the left-hand side of a compound boolean term by another
      boolean term.

\end{itemize}

% }}}

Fortunately, this wishlist is not at all utopian. All the information
necessary to generate an \api, and (much more important) an actual
\emph{implementation} of such an \api, is present in the \sdf-definition.

Because we want to generate code in a variety of target languages, we
opted for a ``frontend-backend'' approach. First the necessary information
is extracted from an \sdf\ specification into a proprietary intermediate
format (frontend), which is then be re-used in several code-generation
phases (backend).

The intermediate format is called \emph{annotated data type}, or \adt\
for short. It holds the minimal amount of information for each syntax
rule in the original \sdf\ specification. In particular, for each rule
we need:

% {{{  The necessary elements of an adt-entry

\begin{itemize}

\item The \emph{sortname} of the production. In our boolean syntax this
is \texttt{Bool};

\item The \emph{alternative} of the production. Our boolean syntax
has five alternatives: \texttt{true}, \texttt{false}, \texttt{not},
\texttt{and}, \texttt{or}.

\item The actual \aterm-\emph{pattern} representation of the rule.
In this pattern, each \emph{field} (non-terminal in the syntax rule)
is replaced by a typed placeholder containing the \emph{sort} of the
non-terminal and a \emph{descriptive name}. For the \texttt{and} rule
we could use \texttt{lhs}, and \texttt{rhs}, both of type \texttt{Bool}.

\end{itemize}

% }}}
% {{{  Example adt-entry with explanation

In the example of the boolean conjunction, we know that the sortname of
the production is \texttt{Bool}, the alternative is called \texttt{and}.
There are two operands, \texttt{lhs} and \texttt{rhs}, both of type
Bool.  In the pattern we put typed placeholders \texttt{<lhs(Bool)>}
and \texttt{<rhs(Bool)>} at the location of the nonterminals. Also,
because the \aterm\ pattern is a parse tree pattern, we have to deal
with any whitespace (layout) that might occur in the terms. Layout can
occur both after the non-terminal \texttt{lhs}, and after the literal
\texttt{and}. The \adt\ entry thus becomes:

\begin{scriptsize}
\begin{verbatim}
 1  [Bool,
 2   and,
 3   appl(prod(
 4    [cf(sort("Bool")),cf(opt(layout)),lit("and"),cf(opt(layout)),cf(sort("Bool"))],
 5     cf(sort("Bool")),attrs([assoc(left)])),
 6    [<lhs(Bool)>,<ws-after-lhs(Layout)>,lit("and"),<ws-after-and(Layout)>,
 7     <rhs(Bool)>])]
\end{verbatim}
\end{scriptsize}

The sortname is in line $1$, the alternative is seen in line
$2$. Following, in lines $4-7$ is the \aterm\ pattern of the actual
parse tree. Lines $3-5$ spell out the \texttt{prod} of the \asfix\
function application.  Lines $7-8$ show the \texttt{args} part. Clearly
visible are the typed placeholders for \texttt{lhs} and \texttt{rhs},
as well as the two placeholders matching optional layout. We gave them
somewhat arbitrary names \texttt{ws-after-lhs}, and \texttt{ws-after-and}
respectively.

% }}}

% }}}
% {{{  Deriving the \adt\ from a \sdf\ specification

\section{Deriving the \adt\ from a \sdf\ specification}
\label{sec:sdf-to-adt}

Now that we know what information we would like to have, how do we get
it from the \sdf\ definition? If we look back at our \sdf\ definition
of the booleans, we can derive some of the information already. The
result \emph{sort} of a syntax rule is easy: it is explicitly mentioned
at the end of each rule. The \aterm\ pattern is relatively easy, as we
know the \sdf\ normalization rules and the underlying \asfix\ format that
is used in the \metaenv. We can follow the same rules to find the \aterm\
pattern that represents the syntax rule in actual parse trees.

But what about the \emph{alternative} and the \emph{descriptive} names
for the non-terminals that we need? Given our \sdf\ rule for the boolean
\texttt{and}, can we derive a sensible name for each of the \texttt{Bool}
non-terminals? The only information we have is our syntax rule:
{\small\texttt{Bool "and" Bool -> Bool \{left\}} }

If we use heuristics to call them e.g. \texttt{lhs} and \texttt{rhs},
what do we do when we find another syntax rule that has three, four
or even more arguments? In syntax rules with only one non-terminal,
we could default to using the sort name of that non-terminal. But in
general, it is hard to come up with any kind of descriptive naming scheme.
Keep in mind that most toolbuilders will not really be happy if they are
confronted with access functions that have arbitrary generated names,
or numbered arguments. Instead of coming up with any heuristic, we
opted to use the \emph{labeling} mechanism present in \sdf, to label
each non-terminal. This eliminates the need to invent a descriptive
name altogether. Our syntax rule for \texttt{and} becomes: {\small
\texttt{lhs:Bool "and" rhs:Bool -> Bool \{left\}} }

Similarly, we need a solution for the \emph{alternative} name. In this
case the literal \texttt{and} is exactly the name we want. But what
if there is no literal at all? Or what if the literal is some sort of
baroque lexical expression (think of the \C\ and \java\ symbols \verb+&&+
for conjunction). Again we are saved by \sdf, as it provides a way to
annotate syntax rules. In fact, we will re-use the annotation which is
quite commonly used in \sdf\ syntax files to annotate the name of the
\emph{abstract syntax} node that corresponds to this particular syntax
rule. Traditionally the \texttt{cons} annotation is used for this purpose.
So, finally our \texttt{and} syntax rule becomes:
{\small {\texttt{lhs:Bool "and" rhs:Bool -> Bool \{left, cons("and")\}} }

% }}}
% {{{  Code generation from \adt\ to \C

\section{Code generation from \adt\ to \C}
\label{sec:adt-to-c}

\subsection{Generated types and functions}
For each sortname in an \adt, we generate:
% {{{  Generated items

\begin{itemize}

\item An opaque type definition to distinguish instances of this
      particular sort from other \aterms.

\item Conversion functions \texttt{fromTerm} and \texttt{toTerm}
      to interface with generic \atlib-functions, such as
      \texttt{ATreadFromFile}. These functions perform a type cast,
      and as such form the entry and exit points to type safety.

\item A validity function to test whether an instance of a sort
      is indeed valid, i.e. that it indeed matches one of the
      \aterm-patterns defined as an alternative of this sort. This is
      useful to assert the validity of an externally acquired instance
      of this sort, e.g. if it has just been read from file.

\item Constructor functions for each possible alternative for this
      sort to create instances from scratch.

\item An equality function to test equality with another instance of
      this sort.

\item For each alternative of the sort, an \texttt{isAlternative} function
      that checks if the current object is an instance of that particular
      alternative.

\item For each field used in any of the alternatives of the sort,
      a \texttt{hasField} function that checks if the current object is
      an instance of an alternative that has that non-terminal.

\item Similarly, a \texttt{getField} and \texttt{setField} method for
      each of the fields in a sort.

\end{itemize}

% }}}

\subsection{Implementation}

In order to isolate the \aterm-patterns as much as possible from
the actual code, we generate a separate \C\ file for them. This
\emph{dictionary} file declares a separate \afun\ variable for each
\aterm\ function symbol, as well as a separate \aterm\ variable for each
possible pattern. An initialization function is also generated which
takes care of the proper initialization of all these variables, and
which protects them from garbage collection by the built-in collector.
A verbatim dump of all the patterns is included in a comment section in
the generated code, to provide debugging feedback when necessary.

The actual implementation of the \api\ functions is generated in its own
\C\ file, accompanied by a header file containing the signatures of all
exported \api\ functions.

% {{{  fig:Bool.c

\begin{figure}
\hrulefill
\begin{scriptsize}
\begin{verbatim}
  typedef struct _Bool *Bool;                  // opaque type
 
  Bool  BoolFromTerm(ATerm t);                 // conversion functions
  ATerm BoolToTerm(Bool arg);
 
  ATbool isEqualBool(Bool arg0, Bool arg1);    // equality function
 
  ATbool isValidBool(Bool arg);                // validity test
 
  ATbool isBoolTrue(Bool arg);                 // inspectors
  ATbool isBoolOr(Bool arg);
  ...
  ATbool hasBoolLhs(Bool arg);                 // query accessors
  ATbool hasBoolRhs(Bool arg);
  ..
  Bool getBoolLhs(Bool arg);                   // get/set accessors
  Bool setBoolLhs(Bool arg, Bool lhs);
\end{verbatim}
\caption{
  \label{fig:Bool.c}
  Part of the generated \C\ code \texttt{Bool.c}
}
\end{scriptsize}
\hrulefill
\end{figure}

% }}}

% }}}

% {{{  Bibliography

\bibliographystyle{alpha}
\bibliography{apigen}

% }}}
% {{{  Appendix

\appendix

% {{{  Concrete Syntax of ATerms

\section{Concrete Syntax of \aterms}
\label{app:aterm-syntax}
A formal definition of the concrete syntax for \aterms\ using \sdf\
is presented here.

\begin{scriptsize}
\verbatiminput{ATerms.sdf}
\end{scriptsize}

% }}}
% {{{  Concrete Syntax of AsFix

\section{Concrete Syntax of \asfix}
\label{app:asfix-syntax}
A formal definition of the concrete syntax for \asfix\ using \sdf\
is presented here.

\begin{scriptsize}
\verbatiminput{Symbol.sdf}
\verbatiminput{Tree.sdf}
\verbatiminput{Attributes.sdf}
\end{scriptsize}

% }}}

% }}}

\end{document}
