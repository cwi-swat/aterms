%
% File: apigen.ltx
%
% $Id$
%

\documentclass{elsart}

% {{{  packages

\usepackage{verbatim}

% }}}
% {{{  commands

\newcommand{\C}{\mbox{\sc C}}
\newcommand{\adt}{\mbox{\sc adt}}
\newcommand{\afun}{\texttt{AFun}}
\newcommand{\api}{\mbox{\sc api}}
\newcommand{\asdf}{\mbox{\sc Asf+Sdf}}
\newcommand{\asfix}{\mbox{AsFix}}
\newcommand{\asf}{\mbox{\sc Asf}}
\newcommand{\aterms}{\mbox{ATerms}}
\newcommand{\aterm}{\mbox{ATerm}}
\newcommand{\atlib}{\mbox{ATerm-Library}}
\newcommand{\autocode}{\mbox{\sc autocode}}
\newcommand{\java}{\mbox{\sc Java}}
\newcommand{\metaenv}{{\sc Asf+Sdf}\ Meta-En\-vir\-on\-ment}
\newcommand{\sdf}{\mbox{\sc Sdf}}

\newcommand{\heading}[1]{\noindent\textbf{#1}}

% }}}
% {{{  snippet environment

\newenvironment{snippet}{\begin{scriptsize}}{\end{scriptsize}}

% }}}

\begin{document}

% {{{  Frontmatter

\begin{frontmatter}

\title{Generation of \\
  Abstract Programming Interfaces \\
  from Syntax Definitions \\
  $Revision$}

\author{H.A. de Jong \and P.A. Olivier}
\address{
  CWI, Department of Software Engineering, \\
  Kruislaan 413,
  1098 SJ Amsterdam,
  The Netherlands
}

\begin{abstract}
\label{abstract}

Using the \atlib\ to represent tree-like datastructures has become a
popular activity, especially amongst developers of e.g. lexical scanners,
parsers, rewrite engines and model checkers. Practical experience with the
\atlib\ in the \metaenv\ has shown that the development and maintenance
of tools that access \aterms\ using handcrafted code is involved and
very error prone. Both the \emph{make and match} paradigm and the
\emph{direct manipulation} of \aterms\ suffer from the fact that the
programmer uses knowledge about the underlying structure of the \aterm\
that represents the data type being accessed. Hardwiring this knowledge
in various tools makes it difficult to maintain the tools with respect
to changes in the datastructure.

By lifting the data definition and its mapping to an \aterm\
representation away from the level of tool implementation, it becomes
possible to generate a library of access functions on the data type,
which can be used by all the tools that need access to it. The tools no
longer directly manipulate the \aterm\ representation, but rather invoke
methods described by the \api\ of the library, thus abstracting from
the fact that \aterms\ are used for the implementation of the data type.

This paper describes how an \api\ and its implementation can be generated
from a syntax definition of the data type. In particular we describe
how an annotated \sdf\ specification can be used to generate a library
of access functions that manipulate the parse trees of terms over this
syntax. Application of this technique in the \metaenv\ has resulted in
a spectacular elimination of 47\% of the handwritten code, thus greatly
improving both maintainability of the tools and their flexibility with
respect to changes in the parsetree format.

\end{abstract}

\end{frontmatter}

% }}}
% {{{  Introduction


\section{Introduction}
\label{sec:intro}

Since the development of the \atlib~\cite{BJKO2000} in 1999, its use
for the implementation of tree-like data structures has become quite
popular amongst developers of scanners, parsers, rewrite engines and
model checkers. Apart from its inevitable deployment in the tools of
the \metaenv\ for which it was specifically designed, the \atlib\ is
used amongst others in: the ELAN system~\cite{BR01}, The implementation
of the Stratego Language~\cite{Vis01.rta}, CASL~\texttt{MISSING REF},
and the $\mu$CRL ToolSet~\cite{mucrl-toolset}.

As more and more tools in the \metaenv\ were converted to work with
the \atlib, it became apparent that the tools had become inflexible with
respect to changes in the parse tree format (called \asfix), and were hard
to maintain. The reason behind this inflexibility was the fact that all
tools used manually encoded structural knowledge about the location of
data elements inside their \aterm\ representation. With such knowledge
hardwired into the tools it becomes difficult, if not impossible, to
change the \aterm\ representation of the data type.

The coding practise that uses such structural knowledge is not in any
way restricted to the realm of parse trees. In fact, anyone who has
programmed with the \atlib, will probably be familiar with patterns such
as \texttt{and(<bool>,<bool>)}. And given such a pattern, what could
be easier than writing a function that extracts the left-hand side?
But as these patterns become longer and more intricate with a liberal
sprinkling of quoted strings containing backslash-escaped quotes,
and as they begin to contain lists and annotations, the once so simple
\emph{make-and-match} paradigm becomes a developer's nightmare.

Motivated by the desire to change \asfix\ and to avoid the herculean
maintenance task this operation would impose on our tools, we decided
to remove as much ``\aterm-handicraft'' from the tools as possible
by developing an \api-generator that creates both an interface and an
implementation of data structures represented by \aterms.

While maintaining the advantages of the \atlib\ (in our case most notably
its efficiency due to maximal subterm sharing), applications built with
this generated \api\ benefit from improved simplicity and readability,
are easier to maintain, and are more robust against changes in the
underlying \asfix\ representation.

This paper describes how an annotated grammar or syntax definition
can be used to generate a library of functions that provide access to
the parse trees of terms over this grammar. In particular we describe
how a \sdf-specification commonly found when using the \metaenv\ is
used to collect the information necessary to build a mapping between
grammar productions and their \aterm-pattern in the underlying \asfix\
parse tree, and how this mapping is subsequently used to generate \C\
functions that provide an \api\ to these parse trees.

Before getting to the core of the generation scheme, we
present introductory sections on the specification formalism
\asdf\ (Section~\ref{sec:asdf-nutshell}), the syntax of
\aterms\ (Section~\ref{sec:aterm-syntax}), and \asfix\
(Section~\ref{sec:asfix-syntax}).

% {{{  subsection{\asdf\ in a nutshell}

\subsection{\asdf\ in a nutshell}
\label{sec:asdf-nutshell}

The specification formalism \asdf~\cite{BHK89,HHKR92} is a combination of
the algebraic specification formalism \asf\ and the syntax definition
formalism \sdf. An overview can be found in~\cite{DHK96}. As an
illustration, Figure~\ref{fig:bool-example} presents the definition of
the Boolean datatype in \asdf. \asdf\ specifications consist of modules,
where each module has an \sdf-part (defining lexical and context-free
syntax) and an \asf-part (defining equations). The \sdf\ part corresponds
to signatures in ordinary algebraic specification formalisms. However,
syntax is not restricted to plain prefix notation but instead arbitrary
context-free grammars can be defined. The syntax defined in the \sdf-part
of a module can be used immediately when defining equations, thus making
the syntax used in equations \emph{user-defined}.

% {{{  fig:bool-example

\begin{figure}
\begin{snippet}
\hrulefill
\verbatiminput{bool.example}
\caption{\label{fig:bool-example} \asdf\ specification of the Booleans}
\hrulefill
\end{snippet}
\end{figure}

% }}}

The equations appearing in the \asf-part of a specification have the
following distinctive features:

\begin{itemize}
  \item Conditional equations with positive and negative conditions.
  \item Non left-linear equations.
  \item List matching.
  \item Default equations.
\end{itemize}

It is possible to execute specifications by interpreting the equations as
conditional rewrite rules.  The semantics of \asdf\ are based on innermost
rewriting. Default equations are tried when all other applicable equations
have failed, either because the arguments did not match or because one
of the conditions failed.

One of the powerful features of the \asdf\ specification language is
list matching. Figure~\ref{fig:set-example} shows a single equation which
removes multiple occurrences of identifiers from a set. In this example,
variables with a {\tt *} in their name are list-variables that may match
zero or more identifiers. The implementation of list matching may involve
backtracking to find a match that satisfies the left-hand side of the
rewrite rule as well as all of its conditions. Backtracking is only
performed within the scope of a rewrite rule, so if the right-hand side
of the rewrite rule is normalized and this normalization fails {\em no}
backtracking is performed to find a new match.

The development of \asdf\ specifications is supported by an interactive
programming environment, the \metaenv~\cite{Kli93}. In this environment
specifications can be developed and tested. It provides syntax-directed
editors, a parser generator, and a rewrite engine. Given this rewrite
engine terms can be reduced by interpreting the equations as rewrite
rules. For instance, the term
\begin{quote}
  {\tt true \& ( false | true )}
\end{quote}

reduces to {\tt true} when applying the equations of
Figure~\ref{fig:bool-example}.

% {{{  fig:set-example

\begin{figure}
\begin{snippet}
\hrulefill
\verbatiminput{set.example}
\caption{\label{fig:set-example} \asdf\ specification of the Set equation}
\hrulefill
\end{snippet}
\end{figure}

% }}}

% }}}
% {{{  \subsection{Annotated Terms: the \aterm\ syntax}

\subsection{Annotated Terms: the \aterm\ syntax}
\label{sec:aterm-syntax}

The definition of the concrete syntax of \aterms\ is given in
Appendix~\ref{app:aterm-syntax}. Here are a number of examples to
(re-)familiarize the reader with some of the features of the textual
representation of \aterms:

\begin{itemize}

\item Integer and real constants are written conventionally: \texttt{1},
\texttt{3.14}, and \texttt{-0.7E34} are all valid \aterms.

\item Function applications are represented by a function name followed
by an open parenthesis, a list of arguments separated by commas, and a
closing parenthesis. When there are no arguments, the parentheses may be
omitted. Examples are: \texttt{f(a,b)} and \texttt{"test!"(1,2.1,"Hello
world!")}. These examples show that double quotes can be used to delimite
function names that are not identifiers.

\item Lists are represented by an opening square bracket, a number
of list elements separated by commas and a closing square bracket:
\texttt{[1,2,"abc"]}, \texttt{[]}, and \texttt{[f,g([1,2],x)]} are
examples.

\item A placeholder is represented by an opening angular bracket followed
by a subterm and a closing angular bracket. Examples are: \texttt{<int>},
\texttt{<[3]>}, and \texttt{<f(<int>,<real>)>}.

\end{itemize}

% }}}
% {{{  \subsection{\asdf\ Parse Trees: the \asfix\ syntax}

\subsection{\asdf\ Parse Trees for Dummies: \asfix\ explained}
\label{sec:asfix-syntax}

From a \sdf-specification, a parse table can be generated using the
\texttt{pgen} tool from the \metaenv. This parse table can subsequently
be used by \texttt{sglr}: the scannerless, generalized LR parser to
parse input terms over the syntax described by the \sdf-specification.
The result of a succesful parse is a parse tree. The data structure used
to represent parse trees is called \asfix, and is implemented using the
\atlib\ to exploit the maximal subterm sharing that is commonly present
in parse trees.

Because \asfix\ is a parse tree format (as opposed to an abstract syntax
tree), layout in the input term is preserved, and other syntax-derived
facts such as associativity and constructor information is made available
to any tool that has access to the \asfix\ representation of the input
term.

The definition of the concrete syntax of \asfix\ is given in
Appendix~\ref{app:asfix-syntax}, but to quickly familiarize the reader
with \asfix, we show some of its idiosyncrasies by means of real life
examples.

\hrulefill\nopagebreak

\textbf{Example: grammar production \texttt{"true" -> Bool}}

\nopagebreak
The \asfix\ representation of the \sdf\ production
\begin{quote}
  \verb+"true" -> Bool+
\end{quote}
is:
\begin{verbatim}
  prod([lit("true")],cf(sort("Bool")),no-attrs)
\end{verbatim}
\medskip
The literal \texttt{true} is the only element in the lefthand side 
of the production. It is injected into the sort \texttt{Bool}.

\hrulefill\nopagebreak

\textbf{Example: grammar production \texttt{Bool "and" Bool -> Bool \{left\}}}

\nopagebreak

The \asfix\ representation of the grammar production

\begin{quote}
{\footnotesize\verb+Bool "and" Bool" -> Bool {left}+}
\end{quote}

looks like this:

\begin{snippet}
\begin{verbatim}
 1  prod([cf(sort("Bool")),cf(opt(layout)),lit("and"),cf(opt(layout)),cf(sort("Bool"))],
 2    cf(sort("Bool")),
 3    attrs([assoc("left")]))
\end{verbatim}
\end{snippet}

\begin{itemize}

\item Line 1 declares this to be a grammar production (\texttt{prod}),
containing al the elements of the lefthand side of the production. The
\sdf-normalizer has inserted \texttt{cf(opt(layout))} subterms at every
location where optional layout in the input term is allowed.

\item Line 2 tells us that the result sort of this production is
\texttt{Bool}.

\item Line 3 show the attributes associated with this production. In
this case the only attribute is \texttt{left} for left-associativity.

\end{itemize}

\hrulefill\nopagebreak

\textbf{Example: parsed term \texttt{true and false}}

\nopagebreak

If the input term

\begin{quote}
  \texttt{true and false}
\end{quote}

is parsed, the resulting parse tree is the production from the previous
example, applied to the actual argument \texttt{true and false}. The
layout in the input term consists of exactly one space immediately before
and after the keyword \texttt{and}.

\begin{snippet}
\begin{verbatim}
 1 appl(
 2  prod([cf(sort("Bool")),cf(opt(layout)),lit("and"),cf(opt(layout)),cf(sort("Bool"))],
 3       cf(sort("Bool")),attrs([assoc("left")])),
 4 [appl(prod([lit("true")],cf(sort("Bool")),no-attrs),[lit("true")]),
 5  layout([" "]), lit("and"), layout([" "]),
 6  appl(prod([lit("false")],cf(sort("Bool")),no-attrs),[lit("false")])])
\end{verbatim}
\end{snippet}

\begin{itemize}

\item Line 1 states that this tree is the application of a grammar
production to a specific term.

\item Lines 2--3 show the representation of \texttt{Bool "and" Bool ->
Bool \{left\}} from the previous example.

\item Line 4 shows the application of the production \texttt{"true" ->
Bool} to the literal \texttt{true}.

\item Line 5 contains the instantiated optional layout terms. In this
case the input term contained exactly one space immediately before and
just after the keyword \texttt{and}.

\item Similar to line 4, line 6 represents the literal \texttt{"false"}.

\end{itemize}

\hrulefill

The fact that many tools in the \metaenv\ need to operate on such
parse trees, raises the question of how best to access this \aterm\
representation of a data type.

% }}}

% {{{  Accessing \aterm\ Data Types

\section{Accessing \aterm\ Data Types}
\label{sec:aterm-access}

The \atlib\ provides two levels of access to \aterms. We briefly discuss
both of them (Sections~\ref{sec:aterm-lvl1}~and~\ref{sec:aterm-lvl2}) by
showing some examples using the \C\ implementation of the \atlib. Similar
statements are needed when using the \java\ implementation.

Section~\ref{sec:asfix-access} shows the typical way tools in the
\metaenv\ used to access \asfix\ parse trees. As \asfix\ terms are of
impressive complexity to the human eye, the code needed to access them
becomes equally complex if it has to be written down manually.

% {{{  Accessing \aterms\ using the Level One interface

\subsection{Accessing \aterms\ using the Level One interface}
\label{sec:aterm-lvl1}

The first level of access functions is through the easy-to-learn
\emph{make and match} paradigm which allows construction of terms by
parsing their string representation. Placeholders in these patterns
are used to designate ``holes'' in the term which are to be filled in
by other variables, including other \aterms\ as well as native types
(\texttt{int}, \texttt{string}, etc.). Terms are constructed using
\texttt{ATmake}, for example:

% {{{  ATmake example

\begin{footnotesize}
\begin{verbatim}
  ATerm t = ATmake("person(name(<str>),age(<int>))", "Anthony", 7);
\end{verbatim}
\end{footnotesize}

Will result in term \texttt{t} being assigned the value:
\begin{quote}
  \texttt{person(name("Anthony"),age(7))}
\end{quote}

% }}}

\noindent Elements from terms can be extracted using \texttt{ATmatch},
for example:

% {{{  ATmatch example

\begin{footnotesize}
\begin{verbatim}
  char *name;
  int age;
  if (ATmatch(t, "person(name(<str>),age(<int>))", &name, &age)) {
    printf("name = %s, age = %d\n", name, age);
  }
\end{verbatim}
\end{footnotesize}

Will result in the variables \texttt{name} and \texttt{age} being
assigned the values \texttt{Anthony}, and \texttt{7}, respectively.
The output of this fragment would thus be:

\begin{quote}
  \texttt{name = Anthony, age = 7}
\end{quote}

In case we are only interested in extracting the \texttt{age} field
and we do not care about the actual value of \texttt{name}, we can pass
\texttt{NULL} instead of the address of a local variable. In this case,
that particular subterm is still used during matching, but its actual
value is never assigned. This allows us to test if a specific term matches
a given pattern, without having to bind every placeholder in the pattern.

% }}}

% }}}
% {{{  Accessing \aterms\ using the Level Two interface

\subsection{Accessing \aterms\ using the Level Two interface}
\label{sec:aterm-lvl2}

The second level of access allows more direct manipulation of \aterms\
by means of access-functions which operate directly on a term or its
subterms. This way of access is more efficient than using the level one
interface, because there is no need to parse a string pattern to find
out which part of the (sub-)term is needed.

For example, consider the term from the previous section:
\begin{quote}
  \texttt{t = person(name("Anthony"),age(7))}
\end{quote}

We can get \texttt{Anthony}'s age by first extracting the \texttt{age}
subterm from \texttt{t}, and subsequently getting the actual \texttt{7}
from this \texttt{age} term:

\begin{quote}
  \texttt{int age = ATgetInt(ATgetArgument(ATgetArgument(t, 1), 0));}
\end{quote}

Note that the exact \emph{location} of the \texttt{age} field in the
\aterm\ representation of the \texttt{person} record is used. If the
structure of the record were to change, e.g. a field for the person's
last name is inserted between the \texttt{name} and the \texttt{age}
fields, the example code would be broken.

Also note that this code does not even check if the term \texttt{t}
is of the right form, i.e. if \texttt{t} satisfies the pattern
\texttt{person(name(<str>),age(<int>))}. On an arbitrary input term,
the age-extraction code will most likely fail and dump core. But if only
correct input terms are given, it is the most efficient way to encode
the extraction of the age subterm in this \aterm\ representation of the
\texttt{person} record.

% }}}

\subsection{Accessing \asfix\ parse trees}
\label{sec:asfix-access}

This Section shows several ways in which \asfix\ terms can be
accessed. The code fragments are typical for the way parse trees are
manipulated in the \metaenv. 

First, we show the \C\ code necessary to construct the boolean term
\texttt{true} which, when yielded by the parser, looks like this:

\begin{snippet}
\begin{verbatim}
   appl(prod([lit("true")],cf(sort("Bool")),no-attrs), [lit("true")])
\end{verbatim}
\end{snippet}

Even for such a simple input term, its \aterm\ representation written
as a \C\ (or \java) string is already quite complex. This is because
we have to escape all the double quotes (the \verb+"+ characters) from
interpretation by the compiler:

% {{{  Parse Tree for "true"

\begin{snippet}
\begin{verbatim}
 ATerm true = ATparse(
   "appl(prod([lit(\"true\")],cf(sort(\"Bool\")),no-attrs),[lit(\"true\")])");
\end{verbatim}
\end{snippet}

% }}}

As another example, consider a \C\ function that extracts the left-hand
side from a boolean conjunction. It needs to match the parse tree
of the incoming term against the pattern for the syntax production:

\begin{quote}
  \texttt{Bool "and" Bool -> Bool \{left\}}
\end{quote}

An implementation using the level one interface would need the pattern
written as a string, with a \texttt{<term>} placeholder at the correct
spot. Because the pattern is written inside a string, we once again
need to escape all quotes.  Moreover, the string representation of the
match-pattern is so long that it does not legibly fit on one line anymore,
and we need to resort to ANSI \C\ string concatenation\footnote{Strings
can be split over multiple lines by ending one line with a \texttt{"}
and starting the next line with another \texttt{"}.} to span the string
over multiple lines.

% {{{  Level One: Extracting lhs from "Bool and Bool -> Bool"

\begin{snippet}
\begin{verbatim}
  ATerm extract_bool_lhs(ATerm t) {
    ATerm lhs;
    char *bool_and_lhs_pattern = 
      "appl(prod([cf(sort(\"Bool\")),cf(opt(layout)),lit(\"and\"),cf(opt(layout)),"
      "cf(sort(\"Bool\"))],cf(sort(\"Bool\")),attrs([assoc(\"left\")])),"
      "[<term>,<term>,lit("and"),<term>,<term>])";
  
    if (ATmatch(t, bool_and_lhs_pattern, &lhs, NULL, NULL, NULL)) {
      return lhs;
    }

    return NULL;
  }
\end{verbatim}
\end{snippet}

% }}}

Could there be a quote missing in the pattern? Are all the \verb+)+,
\verb+]+, and \verb+}+ characters where they should be? Did you expect
\emph{four} \texttt{<term>} placeholders in the pattern (to account for
the lhs, the rhs, as well as the optional layout before and after the
literal \texttt{and})?

Keep in mind that:

\begin{itemize}

\item as long as it is a valid \C\ string, the \C\ compiler is not going
to warn you if you make a mistake (e.g. you wrote \texttt{lit(and)}
instead of \verb+lit(\"and\")+);

\item as long as it is a valid \aterm-pattern, the \aterm\ parser is
not going to warn you if you make a mistake (e.g. you forgot to add
\texttt{<term>} placeholders for the optional layout);

\item if you made any mistakes, your only hope to fix them lies in
visually inspecting the incoming term and the expected matching pattern,
and figuring out why they do not match!

\end{itemize}

An implementation using the level two interface encodes structural
knowledge about the exact location of the \texttt{lhs} in terms of direct
\aterm\ access functions. In particular, recalling that in \asfix\ we
are dealing with \texttt{appl(prod,[args])} patterns, the \texttt{args}
are always the second argument of the \texttt{appl}. If we look closely
at the \asfix\ pattern for our \texttt{and}-terms, we notice that the
\texttt{lhs} is the first element in this list of \texttt{args}. The
extraction function can thus be simplified to the more efficient, but
very type-unsafe and obfuscated:

% {{{  Level Two: Extracting lhs from "true and false"

\begin{snippet}
\begin{verbatim}
  ATerm extract_bool_lhs(ATerm t) {
    ATermList args = ATgetArgument(t, 1);  // get arguments from AsFix "appl"
    return ATgetFirst(args);               // lhs is the first of these args.
  }
\end{verbatim}
\end{snippet}

% }}}

After all, this function would work on any \aterm\ function application
that has (at least) two arguments, the first of which is a list with
(at least) one element.

% {{{  Maintenance issues

\subsection{Maintenance issues}
\label{sec:maintenance}

There are several fundamental maintenance issues inherent in the use
of \aterms\ as a data structure implementation in hand-crafted tools.

\begin{itemize}

\item The esoteric art of writing down multi-line, quote-escaped string
patterns and the subsequent substitution of parts of these patterns to
contain the desired placeholders at the correct locations, is so error
prone that it is almost guaranteed to go wrong at some point. Practical
experience in the \metaenv\ has proven this many times over. Handcrafted
\aterm-patterns proliferate through numerous versions of various tools,
and after a while all sorts of ``mysterious'' bugs creep up where one tool
cannot handle the output of another tool, or simply bails out reporting
that deep down some part of an input term does not satisfy a particular
assertion. Obviously, these errors are often due to pattern mismatches,
misplaced placeholders, or ill-escaped quotes.

\item Even if the patterns are written down correctly, or when the Level
Two interface is used (which doesn't use \aterm-patterns), there is much
work to be done when the application syntax changes.

Suppose for example that we want to change the syntax of our boolean
conjunction from infix notation:

\begin{quote}
  \texttt{Bool "and" Bool -> Bool}
\end{quote}

\noindent
into prefix notation:

\begin{quote}
  \texttt{"and" "(" Bool "," Bool ")" -> Bool}
\end{quote}

\noindent Conceptually nothing has changed: we mean exactly the same
arguments when we address them as \texttt{lhs}, \texttt{rhs}, and
\texttt{result} terms in both syntaxes. However, in the underlying parse
tree the location of \emph{all three} subterms has changed! This in turn
means that all tools that manipulate, e.g. the \texttt{lhs} of boolean
terms, have to be updated to reflect this structural change in position.

In fact, there is hardly any room for flexibility with respect to changes
in the syntax, unless the arguments happen to remain at their original
position. Every tool based on the modified \emph{application syntax}
has to be updated.

\item With such inflexibility with respect to the application syntax
in mind, imagine what would happen if the structure of the parse
trees (\asfix) \emph{itself} were to change! Every tool based on
the \emph{representation} of parse trees would have to be updated to
reflect the structural changes in the format. In our practical case of
the \metaenv\ where we wanted to rid \asfix\ of some legacy constructs,
this meant modification of virtually \emph{every} tool --- an arduous
task indeed!

\end{itemize}

Although this paper uses tools from the \metaenv\ as a running example,
the maintenance issues addressed here are not specific to parse trees
at all. The issues are fundamental to all applications that use \aterms\
as its data structure representation. Many of these issues are also
valid in applications based on other generic data representation formalisms.


% }}}

% }}}

% {{{  From syntax to \api

\section{From syntax to \api}
\label{sec:syntax-to-api}

Abstracting from implementation details about the facts that there
is such a thing as a parse tree format and that this format in turn
is implemented using \aterms, it is easy to name several operations a
toolbuilder would like, given a syntax definition.

% {{{  What you want to be able to do, given an SDF definition

As an example we consider the booleans again. Some of the typical things
a toolbuilder would like to be able to do given the boolean syntax are:

\begin{itemize}

\item Use a type definition for booleans (it is better to have a specific
type \texttt{Bool} than to use the generic \texttt{ATerm} type);

\item Create the basic booleans: \texttt{true} and \texttt{false};

\item Create a compound boolean term using basic and other compound
boolean terms;

\item Given an arbitrary term, test if it is a valid boolean term;

\item Given an arbitrary boolean term, distinguish between a basic
term and a compound term, e.g. by testing if it has a \texttt{lhs}
or \texttt{rhs};

\item Extract the \texttt{lhs} and \texttt{rhs} of a given boolean term;

\item Replace the \texttt{lhs} and \texttt{rhs} of a compound boolean
term by another boolean term;

\item etc.

\end{itemize}

% }}}

Obviously, this list is not exhaustive, but it does form a nice starting
point. Fortunately, all the necessary information can be extracted
from an \sdf-definition of the grammar. In order to separate some
concerns and simplify the generation framework, we split the process
into two steps. First, we extract all the necessary information from the
\sdf-definition, and store it in a convenient format. This step takes
care of the parsing and analysis of the grammar. The second step takes
the intermediate format and does the actual generation for a specific
target language.

We call the intermediate format \emph{annotated data type}, or \adt\
for short. It holds the minimal amount of information for each syntax
rule in the original \sdf\ specification. In particular, for each rule
we need:

% {{{  The necessary elements of an adt-entry

\begin{itemize}

\item The \emph{sortname} of the production. In our boolean syntax this
is \texttt{Bool};

\item The \emph{alternative} of the production. Our boolean syntax
has five alternatives: \texttt{true}, \texttt{false}, \texttt{not},
\texttt{and}, \texttt{or}.

\item The actual \aterm-\emph{pattern} representation of the rule.
In this pattern, each \emph{field} (non-terminal in the syntax rule)
is replaced by a typed placeholder containing the \emph{sort} of the
non-terminal and a \emph{descriptive name}. For the \texttt{and} rule
we could use \texttt{lhs}, and \texttt{rhs}, both of type \texttt{Bool}.

\end{itemize}

% }}}

Since we are solving the maintenance problem of using \aterms\ as a
data type representation, we decided we could very well use an \aterm\
to represent the elements of an \adt. The obvious advantage is that
we get persistency (saving and loading of an \adt) for free, and we do
not need to construct a domain specific language (with its own parser
etc.) which would introduce undesired development-time overhead. Each
entry in the \adt\ consists of the three elements \emph{sortname},
\emph{alternative}, and \emph{term-pattern}, which we can easily
represent as an \aterm-list.  An entire \adt\ consists of nothing more
than a list of such lists. Instead of using a list, each single entry
could also have been represented as a function with three arguments,
but we opted for as little syntactic sugar in the entries as possible,
to simplify development-time debugging.  Remember that an \adt\ entry
contains an \aterm\ pattern and they are hard enough to read, without
the introduction of an extra function-symbol around them.

% {{{  Example adt-entry with explanation

As an example of the concrete representation of an \adt\ entry, let
us look at the boolean \texttt{and}. In this example, we know that
the sortname of the production is \texttt{Bool}, the alternative
is called \texttt{and}.  There are two operands, \texttt{lhs} and
\texttt{rhs}, both of type Bool. In the pattern we put typed placeholders
\texttt{<lhs(Bool)>} and \texttt{<rhs(Bool)>} at the location of
the corresponding nonterminals. Also, because this is a parse tree
pattern, we have to allow layout (whitespace), which in this case can
occur both after the non-terminal \texttt{lhs}, and after the literal
\texttt{and}. The \adt\ entry thus becomes:

\begin{snippet}
\begin{verbatim}
 1  [Bool,
 2   and,
 3   appl(prod(
 4    [cf(sort("Bool")),cf(opt(layout)),lit("and"),cf(opt(layout)),cf(sort("Bool"))],
 5     cf(sort("Bool")),attrs([assoc(left)])),
 6    [<lhs(Bool)>,<ws-after-lhs(Layout)>,lit("and"),<ws-after-and(Layout)>,
 7     <rhs(Bool)>])]
\end{verbatim}
\end{snippet}

Lines 1 and 2 contain the sortname and the alternative, respectively.
Following, in lines 3--7 is the \aterm\ pattern of the actual parse
tree. Lines 3--5 spell out the \texttt{prod} of the \asfix\ function
application.  Lines 6--7 show the \texttt{args} part. Clearly visible
are the typed placeholders for \texttt{lhs} and \texttt{rhs}.

The two placeholders matching optional layout have the somewhat
arbitrary names \texttt{ws-after-lhs}, and \texttt{ws-after-and}.
Section~\ref{sec:sdf-to-adt} elaborates on the naming schemes used to
generate legible, understandable names.

% }}}

% }}}
% {{{  Deriving the \adt\ from a \sdf\ specification

\section{Deriving the \adt\ from a \sdf\ specification}
\label{sec:sdf-to-adt}

Now that we know what specific information we need in the \adt, how do we
get it from the \sdf\ definition? If we look back at our \sdf\ definition
of the booleans, we can derive two of the necessary elements immediately:

\begin{itemize}

\item The result \emph{sort} of a syntax rule. It is explicitly mentioned
at the end of each rule.

\item The \aterm\ pattern. It can be constructed by following the exact
same rules for constructing \asfix\ terms that the \sdf\ normalizer uses.

\end{itemize}

This leaves us with the issue of coming up with a decent name for each
\emph{alternative} production of the same sort, and we still need to
figure out a way to give \emph{descriptive} names to the non-terminals
in the grammar rule.

\noindent\textbf{Naming the nonterminals}

Given our \sdf\ rule for the boolean \texttt{and}, can we derive a
sensible name for each of the \texttt{Bool} non-terminals? The only
information we have is our syntax rule:

\begin{quote}
{\small\texttt{Bool "and" Bool -> Bool \{left\}} }
\end{quote}

If we use heuristics to call them e.g. \texttt{lhs} and \texttt{rhs},
what do we do when we find another syntax rule that has three, four
or even more arguments? In syntax rules with only one non-terminal,
we could default to using the sort name of that non-terminal. But in
general, it is hard to come up with any kind of descriptive naming scheme.
Keep in mind that most toolbuilders will not really be happy if they are
confronted with access functions that have arbitrarily complex names,
or numbered arguments.

Instead of coming up with any kind of heuristic at all, we opted to
use the \emph{labeling} mechanism present in \sdf, which allows grammar
writers to label each non-terminal. This eliminates the need to invent a
descriptive name altogether and provides an understandable link between
items in a grammar rule and their generated access functions. Suppose
we like the abbreviations \texttt{lhs}, and \texttt{rhs}, we could label
the syntax rule for \texttt{and} to become:

\begin{quote}
{\small \texttt{lhs:Bool "and" rhs:Bool -> Bool \{left\}} }
\end{quote}

\noindent\textbf{Naming the alternatives}

Similarly, we need a solution for the \emph{alternative} name. In
this case the literal \texttt{and} happens to be a name we could use.
But what if there is no literal at all? Or if there are multiple literals
in a production, which one should we pick? Should they be concatenated?
What if the literal is some sort of baroque lexical expression (think of
the \C\ and \java\ symbols \verb+&&+ for conjunction). Again we are saved
by \sdf, which provides a way to annotate syntax rules. In fact, we re-use
an annotation which is quite commonly used by \sdf\ syntax writers to
annotate the name of the \emph{abstract syntax} node that corresponds to
this particular syntax rule. Traditionally the \texttt{cons} annotation is
used for this purpose.  So, finally our \texttt{and} syntax rule becomes:

\begin{quote}
{\small \texttt{lhs:Bool "and" rhs:Bool -> Bool \{left, cons("and")\}} }
\end{quote}

% }}}
% {{{  Code generation from \adt\ to \C

\section{Code generation from \adt\ to \C}
\label{sec:adt-to-c}

Given an abstract data type, which is generated from an \sdf\ definition,
but which could also come from any other source, we no longer need to
worry about any \sdf\ peculiarities, or parse tree specifics. Instead,
we can concentrate on generating the desired functionality for a given
target language. In this paper we concentrate on describing the steps
needed to produce legible, type-safe \C\ code. Optimizations to the
generated code can easily be obtained by removing type-safety checks,
resulting in a more efficient production version of the code.

% {{{  Generated types and functions

\subsection{Generated types and functions}
For each sortname in an \adt, we generate the following items:

\begin{itemize}

\item An opaque type definition to distinguish instances of this
particular sort from other \aterms.

\item Conversion functions \texttt{fromTerm} and \texttt{toTerm}
to interface with generic \aterm\ functions, such as
\texttt{ATreadFromFile}. These functions perform a type cast, and as
such they form the entry and exit points to type-safety.

\item A validity function to test whether an instance of a sort is indeed
valid, i.e. that it indeed matches one of the \aterm-patterns defined
as an alternative of this sort. This is useful to assert the validity
of an externally acquired instance of this sort, e.g. if it has just
been read from file.

\item Constructor functions for each possible alternative for this sort
to create instances from scratch.

\item An equality function to test equality with another instance of
this sort.

\item For each alternative of the sort, an \texttt{isAlternative}
function that checks if the current object is an instance of that
particular alternative.

\item For each field used in any of the alternatives of the sort,
a \texttt{hasField} function that checks if the current object is an
instance of an alternative that has that non-terminal.

\item Similarly, a \texttt{getField} and \texttt{setField} method for
each of the fields in a sort.

\end{itemize}

% }}}
% {{{  Implementation

\subsection{Implementation}

In order to address the maintenance issues associated with the
proliferation of \aterm-patterns, we decided it was a good idea to
isolate them as much as possible from the actual code. This is achieved
by generating a separate \emph{dictionary} file containing all the
\aterm\ patterns used by the library. This \emph{dictionary} file
declares a separate \afun\ variable for each \aterm\ function symbol,
and an \aterm\ variable for each possible pattern. An initialization
function is also generated which takes care of the proper initialization
of all these variables, and the necessary calls to \texttt{ATprotect}
to shield them from the built-in garbage collector. A verbatim dump of
all the patterns is included in a comment section in the generated code,
to provide debugging feedback when necessary. An example of a dictionary
file can be found in Appendix~\ref{app:bool_and_dict}.

The actual implementation of the \api\ functions is generated in its
own \C\ file, accompanied by a header file containing the signatures of
all exported \api\ functions. We show abridged snippets of the generated
code. The header file is straightforward, containing merely the opaque
type definition, and the declarations of the functions contained in the
\C\ file.

% {{{  Opaque type definition

\heading{Opaque type definition}

Defining \verb+Bool+ to be a pointer to a non-existant type (in this case
the \texttt{struct \_Bool}, hides the underlying \aterm\ representation
from the point of view of \api\ users. Instances of \texttt{Bool} can
safely be passed around by functions, but any attempt to dereference
such a pointer results in a compile time error.

\begin{snippet}
\begin{verbatim}
  typedef struct _Bool *Bool;
\end{verbatim}
\end{snippet}

% }}}
% {{{  Term convertors

\heading{Term convertors}

These functions perform no real operation, but take care of the
type casting between the generic \aterm\ type and the more specific
\texttt{Bool}.  They are needed as entry and exit points to type-safety
when \atlib\ functions such as \texttt{ATreadFromFile} are used, which
yield an \aterm.

\begin{snippet}
\begin{verbatim}
  Bool BoolFromTerm(ATerm t) { return (Bool)t; }
  ATerm BoolToTerm(Bool arg) { return (ATerm)arg; }
\end{verbatim}
\end{snippet}

For improved efficiency, these functions could easily be replaced by
macros which perform the exact same type cast. Unfortunately, this
irrevocably kills type-safety, because macros are expanded during the
pre-processor phase, without any form of type checking on the arguments
of the macro.

% }}}
% {{{  Equality tests

\heading{Equality tests}

Because \aterms\ are used as implementation, we get the trivial equality
check based on memory address comparison for free. We only need to
provide a type-safe wrapper around \texttt{ATisEqual}.

\begin{snippet}
\begin{verbatim}
  ATbool isEqualBool(Bool arg0, Bool arg1) {
    return ATisEqual((ATerm)arg0, (ATerm)arg1);
  }
\end{verbatim}
\end{snippet}

As with the convertor functions, the equality function can be replaced by
a macro definition (with the same concerns about the loss of type-safety)
for improved efficiency.

% }}}
% {{{  Validity test

\heading{Validity test}

Whenever an \aterm\ is acquired from an external source (e.g. by
reading it from file) and is converted to \texttt{Bool}, programmers
might like to assert that the term satisfies one of the alternatives for
\texttt{Bool}. After all, any valid \aterm\ will happily be parsed by
\texttt{ATreadFromFile} and subsequent conversion by \texttt{TermToBool}
is done without any verification. The \texttt{isValidBool} function
checks whether a given \texttt{Bool} argument is indeed an instance of
one of the correct alternatives.

\begin{snippet}
\begin{verbatim}
  ATbool isValidBool(Bool arg) {
    if (isBoolTrue(arg)) { return ATtrue; }
    else if (isBoolFalse(arg)) { return ATtrue; }
    else if (isBoolNot(arg)) { return ATtrue; }
    else if (isBoolAnd(arg)) { return ATtrue; }
    else if (isBoolOr(arg)) { return ATtrue; }
    return ATfalse;
}
\end{verbatim}
\end{snippet}

As checking the alternatives is expensive, the conversion functions
themselves do not directly invoke \texttt{isValidBool}. Efficiency
of the \texttt{BoolToTerm} function could be traded for even more
robustness, by making it refuse to convert any \aterm\ that does not
satisfy \texttt{isValidBool}.

% }}}
% {{{  Inspector

\heading{Inspector}

Inspecting a \texttt{Bool} to see if it is an instance of a specific
alternative involves matching the argument against the pattern for
that particular alternative. Because matching is (very) expensive,
the result of the most recent match is cached. This caching approach
seems limited, but is useful when multiple subterms of the \emph{same
argument} are accessed. In these cases, sequences of \texttt{getBoolX}
and \texttt{setBoolY} (q.v.) all reuse the (cached) inspection result.

\begin{snippet}
\begin{verbatim}
  ATbool isBoolTrue(Bool arg) {
    static ATerm cached_arg = NULL;
    static int last_gc = -1;
    static ATbool cached_result;

    assert(arg != NULL);

    if (last_gc != ATgetGCCount() || (ATerm)arg != cached_arg) {
      cached_arg = (ATerm)arg;
      cached_result = ATmatchTerm((ATerm)arg, patternBoolTrue);
      last_gc = ATgetGCCount();
    }

    return cached_result;
  }
\end{verbatim}
\end{snippet}

The cached \aterm\ is deliberately \emph{not} protected from garbage
collection. Doing so would result in all inspector functions holding on
to references of \aterms, without the intent of ever dereferencing them
again. This causes memory hogs, because the garbage collector cannot
free the \aterm\ (nor any of its subterms) which happens to have been
the latest argument to an inspector.

Instead, the inspector detects garbage collects (by remembering the
number of collects) and flushes its cached result whenever one or more
collects have been triggered in between calls to the inspector.

% }}}
% {{{  Query accessor

\heading{Query accessor}

The query accessor checks if a given argument has a specific field. It
is implemented by checking if the argument is an instance of any of the
alternatives which has the required field.

\begin{snippet}
\begin{verbatim}
  ATbool hasBoolLhs(Bool arg) {
    if (isBoolAnd(arg)) { return ATtrue; }
    else if (isBoolOr(arg)) { return ATtrue; }
    return ATfalse;
  }
\end{verbatim}
\end{snippet}

% }}}
% {{{  Get accessor

\heading{Get accessor}

The \texttt{get}ter is implemented much like the query accessor. It
inspects the incoming argument to find out of which alternative it is
an instance.  Upon finding the right alternative, it returns the intended
subterm by directly peeking into the \aterm\ representation.

If the production has but a single alternative, no testing is needed
and the requested subterm can be returned immediately.

\begin{snippet}
\begin{verbatim}
SDF:
  "not" arg:Bool -> Bool {cons("not")}

Generated:
Bool getBoolArg(Bool arg) {
    return (Bool)ATelementAt((ATermList)ATgetArgument((ATermAppl)arg, 1), 2);
}
\end{verbatim}
\end{snippet}

If there are multiple alternatives, each is tested in turn, until a
single alternative remains, which must be the right one (since none of
the other alternatives matched, and we assume a valid instance of one
of the alternative productions).

\begin{snippet}
\begin{verbatim}
SDF:
  lhs:Bool "and" rhs:Bool -> Bool {left, cons("and")}
  lhs:Bool "or" rhs:Bool  -> Bool {left, cons("or")}

Generated:
  Bool getBoolLhs(Bool arg) {
    if (isBoolAnd(arg)) {
      return (Bool)ATgetFirst((ATermList)ATgetArgument((ATermAppl)arg, 1));
    }
    else 
      return (Bool)ATgetFirst((ATermList)ATgetArgument((ATermAppl)arg, 1));
  }
\end{verbatim}
\end{snippet}

An obvious optimization would be do detect if there are alternatives
that have the requested field at the same location in the underlying
\aterm\ representation. In this case, the \texttt{isBoolAnd} test can
be eliminated, because both alternatives of \texttt{Bool} that have a
\texttt{lhs}, have it at the exact same position. The condensed version
would look much like the previous \texttt{getBoolArg} and would be much
cheaper since it does not have to do any matching:

\begin{snippet}
\begin{verbatim}
Condensed code for alternatives: "and", "or"
  Bool getBoolLhs(Bool arg) {
    return (Bool)ATgetFirst((ATermList)ATgetArgument((ATermAppl)arg, 1));
  }
\end{verbatim}
\end{snippet}

% }}}
% {{{  Set accessor

\heading{Set accessor}

The implementation of the \texttt{set}ter is again along the same path
as the \texttt{get}ter and the inspector. The main issue here stems from
the fact that \aterms\ are immutable. Consequently, all \texttt{set}ters
need to be of a functional nature. This means that they cannot update
the \aterm\ \emph{in situ}, but instead need to construct a \emph{new}
\aterm, reflecting the desired change.

\begin{snippet}
\begin{verbatim}
  Bool setBoolLhs(Bool arg, Bool lhs)
  {
    if (isBoolAnd(arg)) {
      return (Bool)
        ATsetArgument((ATermAppl)arg,
                      (ATerm)ATreplace((ATermList)ATgetArgument((ATermAppl)arg, 1),
                                       (ATerm)lhs, 0), 1);
    }
    else if (isBoolOr(arg)) {
      return (Bool)
        ATsetArgument((ATermAppl)arg,
                      (ATerm)ATreplace((ATermList)ATgetArgument((ATermAppl)arg, 1),
                                       (ATerm)lhs, 0), 1);
    }
  
    ATabort("Bool has no Lhs: %t\n", arg);
    return (Bool)NULL;
  }
\end{verbatim}
\end{snippet}

As the construction of a new \aterm\ is very expensive to begin with,
the gain of eliminating the test for one of the alternatives (as
implemented in the \texttt{get}ters) is relatively small, which is why
that particular optimization is omitted here. If we have not found a match
after exhaustively testing all the alternatives, the operation is aborted.

% }}}

% }}}

% }}}
% {{{  Code reduction in the \metaenv

\section{Code reduction in the \metaenv}
\label{sec:reduction}

\begin{figure}[htb]
\begin{tabular}{|l|r|r|r|}
\hline
Component     & Before (LOC)  & After (LOC) & Reduction (\%) \\
\hline
asc-support   &		2207  &	      1752  &	21	\\
libasfix      &	       10419  &	      2077  &	80	\\
asfix-tools   &		 466  &	       603  &  -29	\\
asfix2c compiler &	1866  &	      1138  &	39	\\
asf-tools     &		1303  &	       589  &	55	\\
structure editor &	2861  &	      1946  &	32	\\
evaluator     &		4241  &	      4009  &	 5	\\
module-db     &		1809  &	      1244  &	31	\\
\hline
{\bf Total }  &  \textbf{25172} &	\textbf{13358}	    & \textbf{47} \\
\hline

%% in-output     &		 713  &	       812  &  -14	\\
%% pgen	      &		5226  &	      5226  &	 0	\\
%% sglr	      &	       10225  &	     10427  &	-2	\\
%% utils	      &		1356  &	      1363  &	-1	\\
%% \hline
%% \hline
%% \textbf{Total}	      &	       \textbf{42692}  & \textbf{31186}  & \textbf{27} \\ 
%% \hline

\end{tabular}
\caption{\label{fig:reduction}Code Reduction}
\end{figure}


% }}}
% {{{  Related Work

\section{Related Work}
\label{sec:related}

% {{{  Zephyr ASDL

\subsection{Zephyr ASDL}
\begin{itemize}
\item Targeted at compiler building (much like ATerms)
\item Generates data structure implementations in C, C++, Java, Standard ML and Haskell
\item Generates accessors and serialization code (in a compact binary format)
\item Offers a graphical browser and editor for data described in ASDL
\item No sharing
\item No garbage collection (in C/C++)
\end{itemize}


% }}}
% {{{  COM/Corba IDL compiler

\subsection{(D)COM/Corba IDL compiler}
\begin{itemize}
\item Only generate interfaces not implementations
\item Targeted at distributed environments
\item Well-defined mappings to specific target languages (whitepapers)
\item Interface centric instead of datatype centric
\item No sharing
\item No garbage collection (in languages without GC)
\item (D)COM very windows specific
\end{itemize}

% }}}
% {{{  XML access

\subsection{XML access}
Comparable approach: generate classes from schema/DTD representing XML entities.
Typical example: jaxb (http://java.sun.com/xml/jaxb)
\begin{itemize}
\item Java specific
\item XML oriented: classes implement RootElement, XML as exchange format
\item No sharing
\item Code generation can be steered (using a spec. in XML)
\end{itemize}

% }}}

% }}}
% {{{  Conclusions and Future Work

\section{Conclusions and Future Work}
\label{sec:conclusions}

% }}}

% {{{  Bibliography

\bibliographystyle{alpha}
\bibliography{apigen}

% }}}
% {{{  Appendix

\appendix

% {{{  Concrete Syntax of ATerms

\section{Concrete Syntax of \aterms}
\label{app:aterm-syntax}
A formal definition of the concrete syntax for \aterms\ using \sdf\
is presented here.

\begin{scriptsize}
\verbatiminput{ATerms.sdf}
\end{scriptsize}

% }}}
% {{{  Concrete Syntax of AsFix

\section{Concrete Syntax of \asfix}
\label{app:asfix-syntax}
A formal definition of the concrete syntax for \asfix\ using \sdf\
is presented here.

\begin{scriptsize}
\verbatiminput{Symbol.sdf}
\verbatiminput{Tree.sdf}
\verbatiminput{Attributes.sdf}
\end{scriptsize}

% }}}
% {{{  Example generated dictionary file

\section{Example generated dictionary file}
\label{app:bool_and_dict}
An abbreviated version of the generated dictionary file for the
parse tree syntax (\asfix) of the boolean \texttt{and}. Multiple
similar lines have been condensed (\texttt{...}).
\begin{scriptsize}
\verbatiminput{bool_and_dict}
\end{scriptsize}

% }}}
% }}}

\end{document}
