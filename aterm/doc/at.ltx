\documentclass{article}

%{{{ LaTeX configuration

\usepackage{epsfig}
\usepackage{latexsym}
\usepackage{spec/ASF+SDF}
\usepackage{spec/ASF+SDF-options}

\newcommand{\ATerm}{ATerm}
\newcommand{\ATerms}{ATerms}
\newcommand{\AFun}{AFun}
\newcommand{\AFuns}{AFuns}
\def\metaenv{Meta-En\-vir\-on\-ment}
\def\asmetaenv{{\sc Asf+Sdf}\ Meta-En\-vir\-on\-ment}
\def\aterms{\mbox{ATerms}}
\def\aterm{\mbox{ATerm}}
\def\asfix{\mbox{\sc AsFix}}
\def\sdf{\mbox{\sc Sdf}}
\def\asdf{\mbox{\sc Asf+Sdf}}

%}}}

%{{{ Title page

\title{Efficient Annotated Terms}
\author{M.G.J. van den Brand$^{^1}$\\
        H.A. de Jong$^{^2}$\\
        P.A. Olivier$^{^2}$\\
        \vspace{.1cm}\\
        {\small\sl $^1$CWI,
        Department of Software Engineering\vspace{-.2cm}}\\
        {\small\sl Kruislaan 413, 1098 SJ Amsterdam, The Netherlands}
        \vspace{.1cm}\\
        {\small\sl $^1$University of Amsterdam,
        Programming Research Group\vspace{-.2cm}}\\
        {\small\sl Kruislaan 403, 1098 SJ Amsterdam, The Netherlands}
        \vspace{.1cm}\\
        {\small \sl\tt Mark.van.den.Brand@cwi.nl,jong@wins.uva.nl,olivierp@wins.uva.nl}} 

\begin{document}
\maketitle

%}}}

%{{{ Abstract

\begin{abstract}
In this paper, we will introduce the abstract datatype \emph{Annotated Term}
(\emph{\ATerm}).
We will discuss a number of applications of this datatype, and we will
present a time and space efficient implementation of this datatype.
\end{abstract}

%}}}
%{{{ Introduction

\section{Introduction}
Modern software systems consist of components which often
interact with each other using a so-called software coordination
architecture.
The data exchanged and processed by these components may be very diverse.
We developed a common datatype, called \emph{\ATerm},
to be used for the exchange of information
between components but which can also be directly processed by them.

Given the fact that we are working on applications in the area of interactive
programming environments \cite{Kli93.meta,BKMO97}, 
such a common datatype is of great convience
when exchanging data. Typical examples of these applications include
parsers, compilers, typecheckers, and syntax directed editors.
Typical data being exchanged between and processed by these applications
are (abstract) syntax trees.
The \ATerm\ datatype is very close to this kind of
datatype, it is therefore very natural to use \ATerms\ for internal 
computations. By providing a well-defined set of functions it is possible
to perform operations on the \ATerms\ without conversion to component
specific datatypes.

The applications being developed using the interactive programming environment
vary from developing tools for domain specific languages \cite{DK98} 
to development of factories for  renovation of COBOL programs \cite{BSV97}. 
Because of the size of the problems that these applications
need to handle, we need a very efficient implementation of this
datatype, both in time and space requirements.

We will start by describing the intended application domain of
the \ATerm\ datatype in Section \ref{app_domain}. 
After a definition of both the abstract syntax
and concrete syntax of \ATerms\ and a description of the most
important operations defined on \ATerms, 
we will present a number of requirements on the
implementation of this datatype in Section \ref{requirements}.
In Section \ref{design} we will discuss the design of our implementation
followed by an in-depth description of some implementation issues 
in Section \ref{implementation}.

%}}}
%{{{ The application domain

\section{ATerm Functionality}
\label{app_domain}

The applications that will use the \ATerm\ datatype are mainly
in the field of language processing tools, such as programming
environments and program transformation tools.
These tools mainly operate on (abstract) syntax trees where
each node of a tree consists of a function symbol and zero or 
more arguments (descendents). 
The \ATerm\ datatype is also used to represent terms that are
rewritten by rewrite engines such as interpreters and 
compilers \cite{BHKO98}.
Both types of applications, representation of (abstract) syntax trees
and terms in rewrite engines, ask for an efficient representation
of function application. 

Besides these function applications, a small number of other subtypes
are allowed, to make the \ATerm\ datatype more generally applicable.
These subtypes include integer constants, real number constants,
binary large data objects (blobs), lists of aterms, and the special
placeholder subtype that is used to indicate typed holes in \ATerms.

The fact that the \ATerm\ datatype is used within the components
of language processing tools demands extra functionality with respect
to storage facilities of auxilary non-structural information derived by these
components, e.g., a parser may add coordinates to the nodes
describing the actual yield of the node in the text and a formatter
may add font and/or color information used by an editor when displaying
the textual representation of the tree.
So, an \ATerm\ can be extended with a list of \emph{annotations}
(hence the name \emph{Annotated Terms}), and these annotations are used
to add extra information to the \ATerms.

%}}}
%{{{ The ATerm datatype

\subsection{The \ATerm\ Datatype}
\label{aterm}

We describe the datatype called \emph{annotated term} (or \emph{ATerm})
in more detail.
The abstract definition of this datatype is as follows.
\begin{itemize}
\item An integer constant is an \ATerm.
\item A real constant is an \ATerm.
\item A list of zero or more \ATerms\ is an \ATerm.
\item A function application consisting of a function symbol and
      zero or more \ATerms\ (arguments) is an \ATerm.
      The number of arguments of the function is called
      the \emph{arity} of the function.
\item A blob (Binary Large data OBject) containing a length indication
      and a byte array of binary data (possibly of a huge size)
      is an \ATerm.
\item A placeholder term containing an \ATerm\ representing the
      type of the placeholder is an \ATerm.
\item A list of \ATerm\ pairs may be associated with every \ATerm\
      representing a list of $(label,annotation)$ pairs.
\end{itemize}
Each of these constructs except the last one can be seen as a subtype of
the generic type {\tt ATerm}. The last construct is the \emph{annotation
construct}, which makes it possible to annotate terms with transparent
information\footnote{Transparent in the sense that the result of
most operations is independent of the annotations. This makes it easy
to completely ignore annotations. Typical examples of the use of annotations
includes annotating parse trees with positional or typesetting information, 
and annotating abstract syntax trees with the result of typechecking.}.

\subsection{Concrete Syntax}
\label{concrete-syntax}

Besides the abstract syntax described above, we also define a
concrete syntax for \ATerms. The primary reason for having a concrete
syntax is to be able to exchange \ATerms\ in an accessible, human 
readable form. In Section \ref{implementation} we also discuss a compact 
binary format for the exchange of \ATerms\ in a format that is only 
suitable for processing by a machine.

The first section of the concrete syntax definition defines a number
of syntactic features which are not visible to the outside world.
XXX UITBREIDEN XXX

\vspace{0.4cm}
{\NOAUTOHEADER  \input{spec/ATerm.mtx}}
\vspace{0.4cm}
Note that there is no concrete syntax defined for blobs, because 
a humanly readable representation of blobs depends on the type
of data stored in the blob.

\subsection{Constants and Operations}
\label{operations}

Six constants are defined to represent the different subtypes in \ATerms. 
\begin{itemize}
\item {\tt INT}:  An integer term.
\item {\tt REAL}: A real term.
\item {\tt LIST}: A list of terms.
\item {\tt APPL}: A function application.
\item {\tt PLACEHOLDER}: A placeholder term between angled
        brackets.
\item {\tt BLOB}: A term containing binary data.
\end{itemize}
These constants are needed when determining the type of an arbitrary \ATerm.

The \ATerm\ datatype offers thirteen operations to manipulate terms.
These operations take care of reading and writing terms.
There is a predicate to check the equality of two terms.
Two functions {\tt make} and {\tt match} to construct a term
and to take a terms apart, respectively.
Both functions use a string pattern containing placeholders or holes.
These holes determine the places where terms should occur,
an example of a pattern is ``{\tt and(<term>,<term>)}''.
Patterns are in fact comparable to the strings in the print statements
in C.
Furthermore there are three functions to manipulate the annotations.
Finally there exists one function to obtain the (sub)type of a term.

The operations are as follows:
\begin{itemize}

\item {\tt ATerm readFromString(\emph{string})}: Creates a new term by parsing
\emph{string}.
\item {\tt ATerm readFromTextFile(\emph{file})}: Creates a new term by parsing the
data from \emph{file}.
\item {\tt ATerm readFromBinaryFile(\emph{file})}: Creates a new term by reading a
compact, portable, binary representation from \emph{file}. This format
is discussed in Section \ref{baf}.

\item {\tt Boolean writeToTextFile(\emph{term}, \emph{file})}: Write the text
representation of \emph{term} to \emph{file}. Returns {\tt true} for
success and {\tt false} for failure.
\item {\tt Boolean writeToBinaryFile(\emph{term}, \emph{file})}: Write the compact, portable, binary representation of \emph{term} to \emph{file}. Returns
{\tt true} for success, and {\tt false} for failure (see Section \ref{baf}).
\item {\tt String writeToString(\emph{term})}: Return the text representation
of \emph{term} as a string.

\item {\tt ATbool ATisEqual(\emph{t1},\emph{t2})}: Check if two terms are 
equal.

\item {\tt ATerm make(\emph{pattern}, \emph{args})}: This operation returns a new
term created by taking the string pattern, parsing it as a term and filling
 the holes in the resulting term with arguments taken from {\tt args}.
\item {\tt ATermList match(\emph{term}, \emph{pattern})}: Match \emph{term} against
\emph{pattern}, and return a list of subterms matching with placeholders
in \emph{pattern}.

\item {\tt ATerm setAnnotation(\emph{term}, \emph{label}, \emph{annotation})}:
Return a copy of \emph{term} with annotion labeled by \emph{label} changed
to \emph{annotation}.
\item {\tt ATerm getAnnotation(\emph{term}, \emph{label})}:
Retrieve the annotation labeled by \emph{label} of \emph{term}.
\item {\tt ATerm removeAnnotation(\emph{term}, \emph{label})}: Return a copy
of \emph{term} with its annotation labeled by \emph{label} removed.

\item {\tt Integer getType(\emph{term})}: Retrieve the type of a term. This
operation returns one of the constants mentioned above.
\end{itemize}
Although this may seem a rather restricted set of functions, this set
is sufficiently powerful for most users to build simple applications
with the \ATerm\ library.
Yet the set of operations is simple enough to learn in a relatively
short period of time. We refer to this interface as the \emph{level one}
interface of the \ATerm\ datatype.
 
In order to accomodate \ATerm\ ``advanced users'',
we also provide a \emph{level two} interface, 
which provides a more sophisticated
set of datatypes and functions. These extensions are useful only
when more control over the underlying implementation is needed
or in situations where some operations can be implemented using
level one constructs, can be expressed more concisely and implemented more
efficiently using level two constructs.
The level two interface is a strict superset of the level one
interface. A detailed description of the level two interface
can be found in Appendix \ref{level2}.

%}}}
%{{{ Requirements

\section{Requirements on the Implementation}
\label{requirements}

The \ATerm\ library will be used in tools like programming environments and
rewriting engines that must process large terms in an efficient way.
For instance, (abstract) syntax trees contain a lot of redundant 
information which can easily 
be shared to reduce the size of these trees.
In this section we will formulate a number of constraints
that play an important role in the design and implementation of the
\ATerm\ datatype.

The applications we have in mind must be able to handle
large amounts of terms as well as huge terms. 
This observation makes it possible to
formulate a number of efficiency requirements on the implementation of
the \ATerm\ datatype:

\begin{itemize}
\item The memory required to operate on a large number of \ATerms\  
should be as small as possible. 
\item The operations defined on \ATerms\ must be implemented very
efficiently, both in time and space.
\item External storage of \ATerms\ should be very cheap.
\item It should be possible to exchange \ATerms\ between processes
      (possibly running on different processors or even different machines)
      without having to transfer large amounts of data, and without 
      needing excessive amounts of CPU time for (de)compression.
\end{itemize}

We also present a couple of requirements to ensure that the implementation
of the \ATerm\ datatype is easy to use:
\begin{itemize}
\item Automatic garbage collection is very important so users of this
      datatype do not need to deallocate \ATerm\ objects explicitly.
\item The interface of the library should
      be intuitive and it should be as small as possible to avoid a steep
      learning curve. This is among others realized by restricting the 
      level one
      interface to the thirteen operations presented in 
      Section \ref{operations}.
\end{itemize}

Besides these requirements there are a number of practical 
issues to consider that have a great impact on the design,
and that make this a fairly unique problem:
\begin{enumerate}
\item In typical applications less than 0.1 percent of all terms have
      an arity that is higher than 5.
\item The expected lifetime of terms in most applications is very short.
      This means that garbage collection must be fast and should touch
      as few memory locations as possible to improve caching and paging 
      performance.
\item The total memory requirements of an application cannot be estimated
      in advance. It must be possible to allocate more memory incrementally.
\item A lot of applications will use annotations only sparingly. It is
      therefore important that annotations do not add significantly to the
      overall memory requirements when they are not used.
\item In order to have a portable yet efficient implementation, the
      implementation language will be C. This poses some special 
      requirements for the garbage collection strategy\footnote{We also
      implemented the library in Java. In this case, a lot of the issues
      we discuss in this paper are not relevant, either because we can use 
      build-in features of Java (garbage collection), or
      because we just cannot express these low level concerns in Java.}.
\end{enumerate}
     
%}}}
%{{{ Design

\section{Design}
\label{design}

In this section, we will discuss a number of design decisions we made,
all of which are based on the requirements presented in the
previous section. These decisions involve the mechanics behind maximal sharing,
the garbage collection strategy, and the representation of lists.

\subsection{Maximal Sharing}
\label{hashing}
Probably the most important design decision is to base our implementation
of the \ATerm\ datatype on \emph{maximal sharing}. In order to fully exploit
the redundancy that is typically present in terms that are built,
we never create the same term twice. Before a new term is created,
a lookup is done to see if that term already exists. If it exists, the old
version is reused and no new term is created.
This results in maximally shared terms.

This design decision has a number of important consequences:
\begin{itemize}
\item Because terms can be shared without the creator knowing it,
      terms cannot be modified without creating unwanted side effects.
      This means that terms effectively become \emph{immutable} after creation.
      Destructive updates on terms are not allowed.
\item Two terms are only equal when they are physically the same term.
      This means that the equality check on terms can be done in constant
      time, by means of comparing memory addresses.
\end{itemize}

The maximal sharing of terms can only be maintained when we check
at term creation time whether a particular term already exists. The
lookup must be \emph{extremely fast}, in order to ensure efficient term
creation. We use the fastest technique available
in this situation, namely hashing. Using a hash function that depends on the
\emph{addresses} of the function symbol and the arguments of a function
application, we can quickly search the term database to find a function 
application before creating it.

\subsubsection{Collisions}
One of the issues when using hash techniques
is how to handle collisions in the hashtable. The simplest
technique is to linearly chain entries together that hash to the 
same bucket. In this scenario, one pointer is needed in each
object for hash chaining, which in our case means a memory
overhead of about 25 percent. Other solutions for collision
resolution will either increase the memory requirements (e.g.
binary tree chaining), or the CPU requirements for insertions
or deletions (open addressing, see \cite{Knuth73}).
We therefore use linear hash chaining in our implementation. 

\subsubsection{Direct or Indirect Hashing}
Another issue is whether to store all terms directly in
the hashtable, or store only references in the hashtable.
Storing the objects directly in the hashtable has the advantage
that we can save a memory access when retrieving a term.
However, there are severe drawbacks to this approach:
\begin{itemize}
\item We cannot rehash the old terms because rehashing
      means that we have to physically move the objects in memory.
      In a setting where we use C as an implementation language, moving
      objects in memory is not allowed because we can only determine
      a conservative root set and therefore are not allowed to change
      the pointers to roots.
      This would mean that the hashtable could not grow beyond its 
      initial size, clearly an undesirable feature.
\item The internal fragmentation is increased, because empty slots
      in the hashtable are as large as the object size instead of
      only one machine word.
\item We would need a separate hashtable for each term size in order to
      decrease the internal fragmentation. 
\end{itemize}

Because of these problems, we decided to use linear hash chaining
in combination with indirect hashing.
When the load off the hashtable reaches a certain threshold, 
we allocate a larger table, and rehash all the entries of the 
old table in the new one.

%{{{ Garbage collection

\subsection{Garbage Collection}
The most common strategies for automatic recycling of unused space
are reference counting, mark-compact collection, and 
mark-sweep collection. We will discuss these three strategies 
in turn, and explain why we base our design on mark-sweep garbage collection.

\subsubsection{Reference Counting}
Reference counting in its simplest form works by keeping track of the 
number of references to an object. If this number drops to zero, 
there are no more references to this object and it can be reclaimed.

Reference counting has the advantage that unused terms can be reclaimed 
immediately when they become unused, while in the other strategies 
reclamation of space is more batch oriented. 
In most of the target applications this is not a major
issue but it might be important in some cases, especially
in real-time applications where the unpredictable pauses in execution
caused by sweeping garbage collection are unacceptable.

Unfortunately, in languages like C that do not offer much runtime support
for dynamic memory management, the programmer needs to assist
in updating reference counts, for instance at function exit.
Maybe an even bigger disadvantage is that reference counts need to
be updated everytime the number of references to an object changes.
The overall work that has to be done for a pure reference counting
approach is much higher than in the other strategies.

Another disadvantage of reference counting is the space overhead needed 
to store the reference count.
As we shall see later on, it is possible to implement the \ATerm\ datatype
using only a couple of machine words\footnote{We assume a word size
of 4 bytes in this paper.} per object. Adding a whole word
for keeping track of the reference count is therefore unacceptable.

\subsubsection{Mark-compact Garbage Collection}

Mark-compact garbage collection works by periodically copying all
\emph{live} objects to a fresh empty memory space, and freeing the
original space because it only contains unused objects. Although
this strategy has merits, it is unusable in our situation. 
Mark-compact garbage collection assumes that objects
can be relocated to a different memory location, requiring that
all references to objects can be updated.
But when using C as implementation language, we cannot be sure to 
positively identify \emph{all} references to an object without 
support from the programmer.

\subsubsection{Mark-sweep Garbage Collection}

Mark-sweep garbage collection works using three (sometimes two) phases.
In the first phase, all the objects on the heap are marked as `dead'.
In the second phase, all objects reachable from the known set of root
objects are marked as `live'. In the third phase, all `dead' objects
are swept into a list of free objects.

Mark-sweep garbage collection is very attractive, because it
can be implemented in C, both efficiently and without support from the 
programmer or compiler \cite{BW88,Bo93}. 
Mark-sweep collection is more efficient,
both in time and space than reference counting \cite{JL96}.
The typical space overhead for a mark-sweep garbage collection algorithm is
only 1 bit per object.

\subsubsection{Reusing an Existing Garbage Collector}
A number of excellent generic garbage collectors for C are 
freely available, so a legitimate question is why not reuse an
existing implementation instead of implementing our own collector?

We have examined a number of alternatives, but none of these quite 
fit our needs. The Boehm-Weiser garbage collector \cite{BW88} came close,
but we face a number of unusual circumstances that render existing
garbage collectors impractible:

\begin{itemize}
\item The term database (hashtable) always contains references to 
      all objects. It must be possible to instruct the garbage collector
      not to scan this area for roots.
\item After an object becomes garbage, it must also be removed from the
      term database. This means that we need very low level control
      over the garbage collector.
\item The \ATerm\ datatype has some special characteristics that can
      be exploited to dramatically increase performance:
      \begin{itemize}
	\item Destructive updates are not allowed. In garbage collection
              terminology, this means that there are no pointers from
              old objects to young objects. Although we do not exploit
	      it in the current implementation, this characteristic
              makes the use of a \emph{generational} garbage collector
              very attractive.
        \item The overwhelming majority of objects only consists of 
              between 2 and 5 machine words.
	\item Practical experience has shown that not many root pointers
              are kept in static variables or on the generic C heap. 
              Performance can be increased
              dramatically if we eliminate the expensive scan through the
              heap and the static data area for root pointers. 
              The only downside is that we require
              the programmer to explicitly supply us with the set of roots
              that is located on the heap or in static variables.
      \end{itemize}
\end{itemize}
These observations allow us to gain efficiency on several
levels, using everything from low level system 'hacks' to high-level 
algorithm optimizations.

\subsubsection{The Mark-sweep Algorithm}
Given these facts, we opted for a straightforward version of mark-sweep 
garbage collection to reclaim unused terms because this gives us very good
performance in combination with a high level of maintainability of the
code that uses the library.

As we shall see in Section \ref{implementation}, 
most objects consist of only a couple of machine words. 
By restricting the maximum arity of a function, we can also
set an upperbound on the maximum size of objects.
This enables us to base the memory management 
algorithms we use on a small number of block sizes.

Every object contains a single bit used by the mark-sweep algorithm
to indicate 'live' (marked) objects. At the start of a garbage collection,
all objects are unmarked. The garbage collector tries to locate and mark all
live objects. The garbage collector starts by scanning the stack for
and looking for words could be references to objects. When such a
word is found, the object (and the transitive closure of all of the 
objects it refers to) are marked as 'live'. 

This scan of the stack causes all objects referenced from local
variables to be protected from being garbage collected.
Note however that our garbage collector 
is a  conservative collector in the sense that some of the words on the
stack could accidentally look like object references, resulting in objects 
marked as 'live' that are actually garbage.

After this scan of the stack, all objects that are explicitly protected
by the programmer are marked also.

When all live objects are marked, a single sweep through the heap
is used to store all objects that are free in separate lists of free
objects, one list for each object size.

Allocation of objects is now simply a matter of taking the first element
from the appropriate free-list, which is an extremely cheap operation.

%}}}

%{{{ Representation of lists

\subsection{Representation of Lists}
After the function application, the list construct is the second most 
used \ATerm\ construct. A (memory) efficient representation of lists is 
therefore very important. 
Due to the nature of the operations on \ATerm\ lists, there are
two obvious list representations: an array of term references or a linked
list of term references. Experiments have shown that in typical applications
quite varying list sizes are encountered. This renders the array approach 
inferior, because adding and deleting elements of a list would become to
expensive. Consequently, we have opted for the linked list approach.
Lists are constructed using binary list constructors, containing 
a reference to the first element in the list and to the tail of the list.
This makes it very easy to perform the most commonly used operations
on list, namely adding or removing the first element of a list.

Other operations are more expensive, due to the fact that we cannot
allow destructive updates. Adding an element to the tail of a list
for instance, requires $n$ list creation operations, where $n$ is
the number of elements in the newly created list.

%}}}

%}}}
%{{{ Implementation

\section{Implementation}
\label{implementation}

In this section, we will describe some of the more interesting
implementation aspects of the C implementation of the \ATerm\
datatype. We will first present the memory efficient encoding
of \ATerms\ that we have chosen. We will explain how term sharing and
garbage collection can be implemented efficiently using this encoding.
Furthermore, we will describe how the different
operations on \ATerms\ described in Section \ref{aterm}
can be implemented efficiently.

%}}}
%{{{ Term encoding

\subsection{Term Encoding}

After discussing the requirements of the library (Section \ref{requirements}),
and the design (Section \ref{design}), we will now describe the implementation
of the \ATerm\ datatype in C \cite{KR88}

{\tt <PO> need a reference to ANSI-C!}.

An important issue in the implementation is how to represent \ATerms\ 
in such a way that all operations can be performed efficiently, without using
more memory than is absolutely necessary. 
We will first introduce the memory efficient encoding of \ATerms\ we have 
chosen. Then will discuss how this encoding can be used to implement all
operations efficiently, including term sharing and garbage collection.

We assume that one machine word consists
of 4 bytes, which is typical for modern architectures.
Every \ATerm\ object is stored in two or more machine words.
The first byte of the first word is called the \emph{header}
of the object, and consists of three fields (see Figure \ref{header}):

\begin{figure}[htb]
  \centerline{\epsfig{file=header.ps,scale=0.6}}
  \caption{\label{header}The header layout}
\end{figure}
 
\begin{itemize}
\item A field consisting of 1 bit used as a mark flag by the garbage
      collector.
\item A field consisting of 1 bit indicating whether or not this term
      has an annotation or not.
\item A field consisting of 3 bits that indicate the type of the term.
\item A field consisting of 3 bits representing the arity (number of
      pointers to other terms) of this object. When this field
      contains the maximum value of 7, the term must be a function application
      and the actual arity can be found retrieving the arity of the
      function symbol, which will be discussed later.
\end{itemize}
The rest of this word contains either the function symbol, length, or
nothing depending on the type of the node.
This will be discussed in more detail below.
The second word is always used for hashing, 
and links together all terms in the same
hashbucket.

The type of the \ATerm\ determines the exact layout and contents of
the node.
Figure \ref{encoding} shows the encoding of the different term types.\
In the following paragraphs the encodings for the term types 
are described in more detail.

\begin{figure}[!htb]
  \centerline{\epsfig{file=encoding.ps,scale=0.6}}
  \caption{\label{encoding}Encoding of the different term types}
\end{figure}

\paragraph{APPL encoding}
The remaining 3 bytes following the header in the first word are used to
represent the function symbol. The words following the second word contain
references to the function arguments.
In this way, function applications can be encoded in
$2+n$ machine words, with $n$ the arity of the function application.

\paragraph{LIST encoding}
The binary list constructor can be seen as a special function
application with no function symbol and an arity of 2. The
third word points to the first element in the list, this is called
the {\tt first} field, the fourth word
points to the remainder of the list, and is called the {\tt next} field. 
The length of the list is
stored in the three bytes after the header in the first word.
The empty list\footnote{Due to the uniqueness of terms, only
one instance of the empty list is present at any time.}
is represented using a LIST object with empty
first and next fields, and a length of 0.

\paragraph{INT encoding}
In an integer term, the third word contains the integer value.
The arity of an integer term is 0.

\paragraph{REAL encoding}
In an real term, the third and fourth word contain the real value 
represented by an 8 byte floating point number.
The arity of a real term is 0.

\paragraph{PLACEHOLDER encoding}
The placeholder term has an arity of 1, where the third
word contains a pointer to the placeholder type.

\paragraph{BLOB encoding}
The length of the data contained in a BLOB term is stored in
the three bytes after the header. A pointer to the actual data
is stored in the third word.

\subsection{Implementation of Term Sharing}

\subsection{Implementation of Garbage Collector}

\subsection{Implementation of Level 1 Operators}

%}}}
%{{{ The Binary ATerm Format (BAF)

\subsection{The Binary \ATerm\ Format (BAF)}
\label{baf}
As discussed in the introduction, the efficient exchange of \ATerms\ 
between processes is very important. The simplest form of exchange 
is the concrete syntax presented in Section \ref{concrete-syntax}.
This would involve pretty printing the term on one side, and parsing it
on the other. There are a number of efficiency problems with this approach:
\begin{itemize}
\item The concrete syntax of \ATerms\ does not take into account any
      of the subterm sharing that is exploited in other parts of the
      implementation. This means that this format is unnecessarily verbose.
\item Parsing of terms is an expensive operation. Function symbols need
      to be rescanned everytime they are encountered and all information about
      the sharing of subterms needs to be rebuild.
\end{itemize}

A better solution would be to exchange a representation
of the term that includes sharing. 
A simple solution would be to exchange the memory dump containing the term,
however,  this is not a solution, because such
a dump contains addresses in the memory space of the sending process
that have no meaning for the receiving process.
We have designed an exchange format called BAF (Binary ATerm Format)
that preserves the sharing information in a compact and portable way, 
and is easy to encode and decode. Another important characteristic of
BAF is that it is \emph{compositional}. You can take two or more terms
in BAF format, simply concatenate them and add a function symbol to build 
a more complex term in BAF format. Because the BAF representation of the
argument terms need not be interpreted, this operation can be done very
efficiently even if the argument terms are very large.
The BAF format is readable both by the C implementation as well as
the JAVA implementation of the term library, so it is in fact implementation
independent.

\subsubsection{The BAF Virtual Machine}
A term in BAF format consists of a stream of bytes representing instructions
for a very simple virtual machine. The BAF virtual machine consists of
three stacks, the term stack, the symbol stack, and the argument stack,
and has an instruction set consisting of ten instructions.
We will discuss these instructions, and show how they are used together
with the three stacks to efficiently encode terms.

\par{\tt RESET}\newline
Every term in BAF format starts with the {\tt RESET} command.
This command contains a magic number, a version indication, and a
size estimate of the term stack.

\par{\tt TPUSH\_INT}\newline
The {\tt TPUSH\_INT} command is used to push an integer term on the
term stack. It has a single argument: the value of the integer term.

\par{\tt TPUSH\_REAL}\newline
The {\tt TPUSH\_REAL} command is used to push a real term on the
term stack. It has a single argument: a string representing the
value of the real-valued term.

\par{\tt TPUSH\_BLOB}\newline
The {\tt TPUSH\_BLOB} command is used to push a blob term on the
term stack. It has a single argument: the binary data that is stored
in the blob.

\par{\tt SPUSH\_SYM}\newline
The {\tt SPUSH\_SYM} command is used to push a new function
symbol on the symbol stack. The command has two arguments: the arity of the 
function symbol and the name of the function symbol.

\par{\tt SPUSH\_QSYM}\newline
The {\tt SPUSH\_QSYM} command is similar to the {\tt SPUSH\_SYM} command,
but is used with quoted function symbols.

\par{\tt TPUSH\_APPL}\newline
The {\tt TPUSH\_APPL} command is used to push a new function application on 
the term stack. This command has one argument: the index of the function
symbol relative to the current top of the symbol stack. The arity of
this symbol is used to pop as many arguments from the argument stack as
needed.

\par{\tt TPUSH\_LIST}\newline
The {\tt TPUSH\_LIST} command pushes a new list on the term stack.
It's single argument indicates the number of terms that are to be
taken of the argument stack and stored in the new list.

\par{\tt APUSH}\newline
The {\tt APUSH} command is used to push a term on the argument stack.
This command has one argument: the index of the argument term 
on the term stack, relative to the current top of the term stack.

\subsubsection{An example}
Lets suppose we want to encode the term {\tt f(g("a","a"),123,g("a","a"))}.
A possible BAF encoding of this term would be:
\begin{verbatim}
RESET      0xBAF, 0x0100, yy
SPUSH_QSYM 0, a
TPUSH_APPL 0
APUSH      0
APUSH      0
SPUSH_SYM  2, g
TPUSH_APPL 0
TPUSH_INT  123
APUSH      1
APUSH      0
APUSH      1
SPUSH_SYM  3, f
TPUSH_APPL 0
\end{verbatim}

After the {\tt RESET} command, the quoted symbol {\tt "a"} of arity
0 is defined. This symbol is used to push the function application {\tt "a"}
on the term stack. This function application is then pushed on the
argument stack twice. These two instances are then used to create
the function application g("a","a"). The integer {\tt 123} is pushed
on the term stack. Now that all arguments of the outer function application
are created, they are pushed on the argument stack and used to create
the final function symbol.

\subsubsection{Binary encoding}
The textual representation of the encoding described above can hardly be 
seen as an improvement over the textual representation of the term.
But this changes when we take a look at the actual binary encoding that
is used describe a term in BAF format.

All numbers used in the BAF format are encoded in such a way that small
integers take less space than large numbers, because small numbers
occur far more often than large numbers. The number of bytes needed to 
encode a number can be found by looking at the number of leading 1
bits in the first byte of the number (with a maximum of 3), and
increasing this number by one.
Numbers between 0 and $2^{7}$ (7 bits) use only one byte:\newline
{\tt 0xxxxxxx}.\newline
Numbers between 0 and $2^{14}$ (14 bits) use two bytes:\newline
{\tt 10xxxxxx, xxxxxxxx}.\newline
Numbers between 0 and $2^{21}$ (21 bits) use three bytes:\newline
{\tt 110xxxxx, xxxxxxxx, xxxxxxxx}.\newline
Numbers between 0 and $2^{28}$ (28 bits) use four bytes:\newline
{\tt 1110xxxx, xxxxxxxx, xxxxxxxx, xxxxxxxx}.\newline
Numbers between 0 and $2^{32}$ (32 bits) use five bytes:\newline
{\tt 11110000, xxxxxxxx, xxxxxxxx, xxxxxxxx, xxxxxxxx}.\newline

Each command of the BAF virtual machine has its own command number,
except for the {\tt APUSH} command. Because this command is used the
most, it is implicitly assumed when a command with a number greater
than 10 is read. In this case, 10 is subtracted from the command
to get the {\tt APUSH} argument, the term index on the term stack
that must be pushed on the argument stack. The other command numbers
are:
\begin{itemize}
\item 0: {\tt RESET}
\item 1: {\tt TPUSH\_APPL}
\item 2: {\tt TPUSH\_INT}
\item 3: {\tt TPUSH\_REAL}
\item 4: {\tt TPUSH\_LIST}
\item 5: {\tt TPUSH\_PLACEHOLDER}
\item 6: {\tt TPUSH\_BLOB}
\item 7: {\tt SPUSH\_SYM}
\item 8: {\tt SPUSH\_QSYM}
\end{itemize}

Strings are encoded by their length indicator followed by their contents.
The length indicator is of course encoded as described above.

\subsubsection{The example again}
Using this mechanism the example described above can be encoded
using the following sequence of bytes (in hexadecimal notation):
\begin{verbatim}
00 8B AF 81 00 04       %% The reset command
08 00 01 61             %% A quoted symbol "a", with arity 0.
01 00                   %% Push application "a" on the term stack.
00                      %% Push application "a" on the argument stack
00                      %% Push application "a" on the argument stack
07 02 01 67             %% An unquoted symbol g, with arity 2.
01 00                   %% Push appl. g("a","a") on the term stack
02 7B                   %% Push integer term 123 on the term stack
01                      %% Push appl. g("a","a") on the argument stack
00                      %% Push integer term 123 on the term stack
01                      %% Push appl. g("a","a") on the argument stack
07 03 01 66             %% Unquoted symbol f with arity 3.
01 00                   %% Push appl. f(g("a","a"),123,g("a","a"))
\end{verbatim}

If we ignore the {\tt RESET} command, we are still left with
25 bytes against the 28 bytes of the original term. The fact that we 
do not gain anything is mainly due to the size of this example.
The overhead of the {\tt SPUSH\_SYM} and {\tt SPUSH\_QSYM} commands 
diminishes as the size of the term increases. The following table
gives an impression of the compression that can be reached in real-world
terms when the term size increases:

%}}}

\section{Major Application: the ASF+SDF Meta-Environment}

\section{Related Work}

\begin{itemize}
\item IDL
\item SGML
\item GEL
\end{itemize}

\section{Conclusions}

\begin{itemize}
\item The average garbage collection time for the applications we developed
using the \ATerm\ library is 5 percent.
\item The \ATerm\ library is powerful enough to develop both memory
and computational applications, e.g., the {\sc Asf+Sdf} compiler \cite{BHKO98}
is entirely based on this library and the application developed by
JanFriso Groote.
\item The current implementation is running on SGI, Solaris, and UNIX.
\item The \ATerm\ library gave rise to an unexpected application,
a tool for detecting code clones in COBOL programs.
\item The using BAF reduces the term size by a factor XXX and reduces the
processing time by a factor XXX.
\end{itemize}

\section{Future work}

\begin{itemize}
\item Generational garbage collector.
\item BAF for JAVA.
\item More compact BAF format.
\item Porting to Windows platform.
\end{itemize}

\bibliographystyle{alpha}
\bibliography{thesis}

\appendix

%{{{ Level 2 interface

\section{Level 2 interface}
\label{level2}
The operations described in Section \ref{aterm} are not sufficient for
all applications. Some applications need more control over the underlying 
implementation, or need operations that can be implemented using
level one constructs but can be expressed more concisely and implemented more
efficiently using more specialized constructs.

We have therefore designed a level 2 interface that is a strict superset of
the level 1 interface described in Section \ref{aterm}. Some new datatypes
are introduced, as well as some new operations on \ATerms.

The level 2 interface introduces 8 new datatypes. The first datatype
represents function application symbols, and is called \AFun.
The other 7 datatypes are subtypes of the \ATerm\ datatype, and implement 
the different term types. These subtypes allow us to introduce operations
that are only valid for one specific term type, instead of the general
\ATerm\ operations described earlier.

%{{{ AFun

\paragraph{\AFun:} An \AFun\ consists of a string defining the function
name, an arity, and an indication whether the symbol name is quoted or not.
The operations on symbols are:
\begin{itemize}
\item {\tt makeAFun(\emph{name},\emph{arity},\emph{quoted})}: Construct
a new symbol. If a symbol with the given name, arity, and quotation already 
exists, the existing symbol is returned. Otherwise a new symbol is created
and returned. \AFuns\ are also subject to garbage collection in order
to avoid long running (interactive) programs from slowly running out of
symbols.
\item {\tt getName(\emph{symbol})}: Retrieve the name of a symbol.
\item {\tt getArity(\emph{symbol})}: Retrieve the arity of a symbol.
\item {\tt isQuoted(\emph{symbol})}: Check if a symbol is quoted.
\end{itemize}

%}}}
%{{{ ATermAppl

\paragraph{ATermAppl:} This datatype represents function applications
consisting of a function symbol and a number of arguments.
The operations on this datatype are:
\begin{itemize}
\item {\tt ATermAppl makeAppl$n$(AFun$\!\!$ \emph{fun}, ATerm \emph{arg}$_0$,
           $\ldots$, ATerm \emph{arg}$_{n-1}$)}:
	  This is a family of operations, one for each $n$ between $0$ and $6$
	  (inclusive). These operations are used to construct a new
	  function application with the given function symbol and 
	  arguments.
\item {\tt ATermAppl makeAppl(AFun \emph{fun}, ATermList \emph{args})}:
		Construct a new function application with the given function
		symbol and arguments.
\item {\tt AFun getFun(ATermAppl \emph{appl})}: 
      Retrieve the function symbol of a function application.
\item {\tt ATerm getArgument(ATermAppl \emph{appl}, int \emph{n})}: 
      Retrieve a specific argument.
\end{itemize}

%}}}
%{{{ ATermList

\paragraph{ATermList:} This datatype represents the binary list constructor.
Element indices start at 0. Thus a list of length $n$ has elements
$0\ldots n-1$.
The operations on ATermList are:
\begin{itemize}
\item {\tt ATermList makeList$n$(ATerm \emph{el}$_0$,$\ldots$,
	       ATerm \emph{el}$_{n-1}$)}:
      This is a family of operations, one for each $n$ between
      $0$ and $6$ (inclusive). These operations are used to quickly construct
	  small lists of terms.
\item {\tt Integer getLength(ATermList \emph{list})}: Retrieve the length of
		\emph{list}.
\item {\tt ATerm getFirst(ATermList \emph{list})}: Retrieve the first element of
	\emph{list}.
\item {\tt ATermList getNext(ATermList \emph{list})}: Retrieve all but the first
	element of \emph{list}.
\item {\tt ATermList getPrefix(ATermList \emph{list})}: Retrieve all but the last
	element of \emph{list}.
\item {\tt ATerm getLast(ATermList \emph{list})}: Retrieve the last element from
      \emph{list}.
\item {\tt ATermList getSlice(ATermList \emph{list}, Integer \emph{start}, 
   Integer \emph{end})}: Retrieve the portion of \emph{list} from position
   \emph{start} through \emph{end-1}. 
\item {\tt Boolean isEmpty(ATermList \emph{list})}: Check if \emph{list}
	contains zero elements.
\item {\tt ATermList insert(ATermList \emph{list}, ATerm \emph{el})}:
      Insert a single element at the start of a list.
\item {\tt ATermList insertAt(ATermList \emph{list}, ATerm \emph{el},
       Integer \emph{index})}:
      Insert a single element at position index in \emph{list}.
\item {\tt ATermList append(ATermList \emph{list}, ATerm \emph{el})}:
      Append a single element to the end of \emph{list}.
\item {\tt ATermList concat(ATermList \emph{list1}, ATermList \emph{list2})}:
      Concatenate \emph{list1} and \emph{list2}.
\item {\tt Integer indexOf(ATermList \emph{list}, ATerm \emph{el},
       Integer \emph{n})}:
      Search for an element in \emph{list} and return the index of the first
      location where \emph{el} is present. Start searching at index \emph{n}.
      If the element is not present after element \emph{n}, return -1.
\item {\tt Integer lastIndexOf(ATermList \emph{list}, ATerm \emph{el},
       Integer \emph{n})}:
      Search backwards for \emph{el} in \emph{list}, and return the index of
	  the last location where the element is present. Start searching 
	at index \emph{n}. 
	If the element is not present before element \emph{n}, return -1.
\item {\tt ATerm elementAt(ATermList \emph{list}, Integer \emph{index})}:
      Retrieve element at position \emph{index} from \emph{list}.
\item {\tt ATermList removeElement(ATermList \emph{list}, ATerm \emph{elem})}:
	Remove once occurence of an element from a list.
\item {\tt ATermList removeElementAt(ATermList \emph{list}, 
	Integer \emph{index})}: Remove an indexed element from a list.
\end{itemize}

%}}}
%{{{ ATermInt

\paragraph{ATermInt:} This datatype represents integer terms.
The operations on ATermInt are:

\begin{itemize}
\item {\tt ATermInt makeInt(Integer \emph{value})}: Construct a new integer
term.
\item {\tt Integer getInt(ATermInt \emph{i})}: Retrieve the value of an 
      integer term.
\end{itemize}

%}}}
%{{{ ATermReal

\paragraph{ATermReal:} This datatype represents real-number terms.
The operations on ATermReal are:

\begin{itemize}
\item {\tt ATermReal makeReal(Real \emph{value})}: Construct a new 
      real term.
\item {\tt double getReal(ATermReal \emph{r})}: Retrieve the value of 
      a real term.
\end{itemize}

%}}}
%{{{ ATermPlaceholder

\paragraph{ATermPlaceholder:} This datatype represents placeholder terms.
The operations on ATermPlaceholder are:

\begin{itemize}
\item {\tt ATermPlaceholder makePlaceholder(ATerm \emph{type})}: 
      Construct a new placeholder term.
\item {\tt ATerm getPlaceholder(ATermPlaceholder \emph{placeholder})}: 
      Retrieve the type of this placeholder.
\end{itemize}

%}}}
%{{{ ATermBlob

\paragraph{ATermBlob:} This datatype represents Binary Large OBject terms.
The memory management of blobs must be done explicitly by the application
programmer. 

%%Blobs are never allocated, freed, or even touched by the
%%\ATerm\ library. 

%%Blob destructors can be registered using the
%%{\tt registerBlobDestructor} function. All registered destructors are
%%called before the space occupied by a `dead' ATermBlob is reused. 

The operations on ATermBlob are:

\begin{itemize}
\item {\tt ATermBlob makeBlob(Integer \emph{size}, Data \emph{data})}: 
      Construct a new blob term.
\item {\tt Integer getBlobSize(ATermBlob \emph{blob})}: Retrieve the size of
      a blob.
\item {\tt Data getBlobData(ATermBlob *\emph{blob})}: Retrieve the data
      pointer stored in a blob.
\end{itemize}

%}}}

%}}}

\end{document}
